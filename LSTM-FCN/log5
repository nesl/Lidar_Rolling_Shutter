2021-09-25 08:52:43.120941: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2021-09-25 08:52:43.120968: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: UNKNOWN ERROR (303)
2021-09-25 08:52:43.120981: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (red-aghast): /proc/driver/nvidia/version does not exist
2021-09-25 08:52:43.121125: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2021-09-25 08:52:43.137637: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2899885000 Hz
2021-09-25 08:52:43.137928: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f00ac000b60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2021-09-25 08:52:43.137962: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
Num datasets :  128

Model: "model_1"
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 1, 70)        0                                            
__________________________________________________________________________________________________
permute_1 (Permute)             (None, 70, 1)        0           input_1[0][0]                    
__________________________________________________________________________________________________
conv1d_1 (Conv1D)               (None, 70, 128)      1152        permute_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 70, 128)      512         conv1d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 70, 128)      0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv1d_2 (Conv1D)               (None, 70, 256)      164096      activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 70, 256)      1024        conv1d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 70, 256)      0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv1d_3 (Conv1D)               (None, 70, 128)      98432       activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 70, 128)      512         conv1d_3[0][0]                   
__________________________________________________________________________________________________
attention_lstm_1 (AttentionLSTM (None, 128)          0           input_1[0][0]                    
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 70, 128)      0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 128)          0           attention_lstm_1[0][0]           
__________________________________________________________________________________________________
global_average_pooling1d_1 (Glo (None, 128)          0           activation_3[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 256)          0           dropout_1[0][0]                  
                                                                 global_average_pooling1d_1[0][0] 
__________________________________________________________________________________________________
dense_1 (Dense)                 (None, 1)            257         concatenate_1[0][0]              
==================================================================================================
Total params: 265,985
Trainable params: 264,961
Non-trainable params: 1,024
__________________________________________________________________________________________________
******************** Training model for dataset  ********************
Finished loading train dataset..
Finished loading test dataset..

Number of train samples :  23436 Number of test samples :  5040
Sequence length :  70
Train on 23436 samples, validate on 5040 samples
Epoch 1/2000
 - 31s - loss: 101514.0085 - val_loss: 94049.7190

Epoch 00001: loss improved from inf to 101514.00850, saving model to ./weights/_weights.h5
Epoch 2/2000
 - 33s - loss: 86586.6772 - val_loss: 81254.5580

Epoch 00002: loss improved from 101514.00850 to 86586.67719, saving model to ./weights/_weights.h5
Epoch 3/2000
 - 33s - loss: 62420.5442 - val_loss: 53268.7857

Epoch 00003: loss improved from 86586.67719 to 62420.54421, saving model to ./weights/_weights.h5
Epoch 4/2000
 - 33s - loss: 38477.7087 - val_loss: 30190.7582

Epoch 00004: loss improved from 62420.54421 to 38477.70873, saving model to ./weights/_weights.h5
Epoch 5/2000
 - 33s - loss: 21379.2000 - val_loss: 21210.5184

Epoch 00005: loss improved from 38477.70873 to 21379.20005, saving model to ./weights/_weights.h5
Epoch 6/2000
 - 33s - loss: 12998.7732 - val_loss: 10992.6012

Epoch 00006: loss improved from 21379.20005 to 12998.77320, saving model to ./weights/_weights.h5
Epoch 7/2000
 - 33s - loss: 9874.1450 - val_loss: 9851.0867

Epoch 00007: loss improved from 12998.77320 to 9874.14498, saving model to ./weights/_weights.h5
Epoch 8/2000
 - 33s - loss: 8896.3877 - val_loss: 13615.0749

Epoch 00008: loss improved from 9874.14498 to 8896.38772, saving model to ./weights/_weights.h5
Epoch 9/2000
 - 33s - loss: 8752.4914 - val_loss: 9372.2537

Epoch 00009: loss improved from 8896.38772 to 8752.49142, saving model to ./weights/_weights.h5
Epoch 10/2000
 - 33s - loss: 8443.4936 - val_loss: 18470.5248

Epoch 00010: loss improved from 8752.49142 to 8443.49357, saving model to ./weights/_weights.h5
Epoch 11/2000
 - 33s - loss: 8367.7689 - val_loss: 8913.1812

Epoch 00011: loss improved from 8443.49357 to 8367.76893, saving model to ./weights/_weights.h5
Epoch 12/2000
 - 33s - loss: 8303.8001 - val_loss: 13423.2410

Epoch 00012: loss improved from 8367.76893 to 8303.80005, saving model to ./weights/_weights.h5
Epoch 13/2000
 - 33s - loss: 8309.0368 - val_loss: 10025.5546

Epoch 00013: loss did not improve from 8303.80005
Epoch 14/2000
 - 33s - loss: 8112.4047 - val_loss: 9197.1954

Epoch 00014: loss improved from 8303.80005 to 8112.40470, saving model to ./weights/_weights.h5
Epoch 15/2000
 - 33s - loss: 8084.6709 - val_loss: 9270.2262

Epoch 00015: loss improved from 8112.40470 to 8084.67094, saving model to ./weights/_weights.h5
Epoch 16/2000
 - 33s - loss: 8102.5381 - val_loss: 10138.3061

Epoch 00016: loss did not improve from 8084.67094
Epoch 17/2000
 - 33s - loss: 7979.5839 - val_loss: 8924.1076

Epoch 00017: loss improved from 8084.67094 to 7979.58386, saving model to ./weights/_weights.h5
Epoch 18/2000
 - 33s - loss: 7945.7814 - val_loss: 12648.0271

Epoch 00018: loss improved from 7979.58386 to 7945.78145, saving model to ./weights/_weights.h5
Epoch 19/2000
 - 33s - loss: 7866.4294 - val_loss: 8072.4792

Epoch 00019: loss improved from 7945.78145 to 7866.42935, saving model to ./weights/_weights.h5
Epoch 20/2000
 - 33s - loss: 7838.4996 - val_loss: 10837.0206

Epoch 00020: loss improved from 7866.42935 to 7838.49964, saving model to ./weights/_weights.h5
Epoch 21/2000
 - 33s - loss: 7744.1096 - val_loss: 9130.8300

Epoch 00021: loss improved from 7838.49964 to 7744.10961, saving model to ./weights/_weights.h5
Epoch 22/2000
 - 32s - loss: 7758.6789 - val_loss: 8347.7435

Epoch 00022: loss did not improve from 7744.10961
Epoch 23/2000
 - 32s - loss: 7646.5958 - val_loss: 14341.4230

Epoch 00023: loss improved from 7744.10961 to 7646.59585, saving model to ./weights/_weights.h5
Epoch 24/2000
 - 33s - loss: 7614.0037 - val_loss: 8376.5744

Epoch 00024: loss improved from 7646.59585 to 7614.00371, saving model to ./weights/_weights.h5
Epoch 25/2000
 - 32s - loss: 7539.7759 - val_loss: 7943.6824

Epoch 00025: loss improved from 7614.00371 to 7539.77592, saving model to ./weights/_weights.h5
Epoch 26/2000
 - 33s - loss: 7503.7246 - val_loss: 7797.9561

Epoch 00026: loss improved from 7539.77592 to 7503.72457, saving model to ./weights/_weights.h5
Epoch 27/2000
 - 33s - loss: 7445.6528 - val_loss: 9481.7406

Epoch 00027: loss improved from 7503.72457 to 7445.65280, saving model to ./weights/_weights.h5
Epoch 28/2000
 - 33s - loss: 7428.3883 - val_loss: 9623.4791

Epoch 00028: loss improved from 7445.65280 to 7428.38826, saving model to ./weights/_weights.h5
Epoch 29/2000
 - 32s - loss: 7385.6673 - val_loss: 10217.4261

Epoch 00029: loss improved from 7428.38826 to 7385.66729, saving model to ./weights/_weights.h5
Epoch 30/2000
 - 33s - loss: 7338.8759 - val_loss: 7740.8395

Epoch 00030: loss improved from 7385.66729 to 7338.87586, saving model to ./weights/_weights.h5
Epoch 31/2000
 - 32s - loss: 7288.0225 - val_loss: 9104.6865

Epoch 00031: loss improved from 7338.87586 to 7288.02249, saving model to ./weights/_weights.h5
Epoch 32/2000
 - 33s - loss: 7205.3243 - val_loss: 7554.6503

Epoch 00032: loss improved from 7288.02249 to 7205.32427, saving model to ./weights/_weights.h5
Epoch 33/2000
 - 33s - loss: 7171.1531 - val_loss: 8062.2246

Epoch 00033: loss improved from 7205.32427 to 7171.15310, saving model to ./weights/_weights.h5
Epoch 34/2000
 - 33s - loss: 7174.0132 - val_loss: 8112.0870

Epoch 00034: loss did not improve from 7171.15310
Epoch 35/2000
 - 33s - loss: 7208.4560 - val_loss: 9417.0107

Epoch 00035: loss did not improve from 7171.15310
Epoch 36/2000
 - 33s - loss: 7104.5290 - val_loss: 7733.8985

Epoch 00036: loss improved from 7171.15310 to 7104.52905, saving model to ./weights/_weights.h5
Epoch 37/2000
 - 33s - loss: 7003.0681 - val_loss: 8636.4373

Epoch 00037: loss improved from 7104.52905 to 7003.06814, saving model to ./weights/_weights.h5
Epoch 38/2000
 - 33s - loss: 7065.5637 - val_loss: 7403.8820

Epoch 00038: loss did not improve from 7003.06814
Epoch 39/2000
 - 33s - loss: 7103.8584 - val_loss: 8192.3078

Epoch 00039: loss did not improve from 7003.06814
Epoch 40/2000
 - 34s - loss: 6981.4653 - val_loss: 16283.5361

Epoch 00040: loss improved from 7003.06814 to 6981.46528, saving model to ./weights/_weights.h5
Epoch 41/2000
 - 34s - loss: 7045.2581 - val_loss: 8179.3813

Epoch 00041: loss did not improve from 6981.46528
Epoch 42/2000
 - 34s - loss: 6865.3994 - val_loss: 7167.5123

Epoch 00042: loss improved from 6981.46528 to 6865.39937, saving model to ./weights/_weights.h5
Epoch 43/2000
 - 34s - loss: 6880.1947 - val_loss: 7190.5866

Epoch 00043: loss did not improve from 6865.39937
Epoch 44/2000
 - 34s - loss: 6765.6350 - val_loss: 7316.8629

Epoch 00044: loss improved from 6865.39937 to 6765.63502, saving model to ./weights/_weights.h5
Epoch 45/2000
 - 34s - loss: 6889.7303 - val_loss: 12235.7492

Epoch 00045: loss did not improve from 6765.63502
Epoch 46/2000
 - 34s - loss: 6804.9598 - val_loss: 7495.5699

Epoch 00046: loss did not improve from 6765.63502
Epoch 47/2000
 - 34s - loss: 6815.1672 - val_loss: 10258.9543

Epoch 00047: loss did not improve from 6765.63502
Epoch 48/2000
 - 34s - loss: 6785.2872 - val_loss: 13092.8135

Epoch 00048: loss did not improve from 6765.63502
Epoch 49/2000
 - 34s - loss: 6598.9050 - val_loss: 14691.7878

Epoch 00049: loss improved from 6765.63502 to 6598.90502, saving model to ./weights/_weights.h5
Epoch 50/2000
 - 34s - loss: 6778.1904 - val_loss: 7992.1966

Epoch 00050: loss did not improve from 6598.90502
Epoch 51/2000
 - 34s - loss: 6605.4212 - val_loss: 9093.5878

Epoch 00051: loss did not improve from 6598.90502
Epoch 52/2000
 - 34s - loss: 6564.3402 - val_loss: 7367.9832

Epoch 00052: loss improved from 6598.90502 to 6564.34019, saving model to ./weights/_weights.h5
Epoch 53/2000
 - 34s - loss: 6673.8084 - val_loss: 6972.6063

Epoch 00053: loss did not improve from 6564.34019
Epoch 54/2000
 - 34s - loss: 6651.8070 - val_loss: 9175.0315

Epoch 00054: loss did not improve from 6564.34019
Epoch 55/2000
 - 34s - loss: 6560.7058 - val_loss: 7208.9553

Epoch 00055: loss improved from 6564.34019 to 6560.70585, saving model to ./weights/_weights.h5
Epoch 56/2000
 - 35s - loss: 6522.2526 - val_loss: 7785.7202

Epoch 00056: loss improved from 6560.70585 to 6522.25264, saving model to ./weights/_weights.h5
Epoch 57/2000
 - 33s - loss: 6404.3827 - val_loss: 7011.2737

Epoch 00057: loss improved from 6522.25264 to 6404.38273, saving model to ./weights/_weights.h5
Epoch 58/2000
 - 33s - loss: 6379.3063 - val_loss: 7128.4199

Epoch 00058: loss improved from 6404.38273 to 6379.30633, saving model to ./weights/_weights.h5
Epoch 59/2000
 - 32s - loss: 6314.8276 - val_loss: 7288.3820

Epoch 00059: loss improved from 6379.30633 to 6314.82764, saving model to ./weights/_weights.h5
Epoch 60/2000
 - 33s - loss: 6385.2095 - val_loss: 8845.6247

Epoch 00060: loss did not improve from 6314.82764
Epoch 61/2000
 - 32s - loss: 6400.3704 - val_loss: 37258.7041

Epoch 00061: loss did not improve from 6314.82764
Epoch 62/2000
 - 33s - loss: 6401.5577 - val_loss: 6819.1664

Epoch 00062: loss did not improve from 6314.82764
Epoch 63/2000
 - 33s - loss: 6272.9437 - val_loss: 10282.2774

Epoch 00063: loss improved from 6314.82764 to 6272.94370, saving model to ./weights/_weights.h5
Epoch 64/2000
 - 33s - loss: 6490.1909 - val_loss: 13656.2172

Epoch 00064: loss did not improve from 6272.94370
Epoch 65/2000
 - 33s - loss: 6345.4598 - val_loss: 7058.5074

Epoch 00065: loss did not improve from 6272.94370
Epoch 66/2000
 - 33s - loss: 6192.5891 - val_loss: 9608.3823

Epoch 00066: loss improved from 6272.94370 to 6192.58910, saving model to ./weights/_weights.h5
Epoch 67/2000
 - 33s - loss: 6248.6577 - val_loss: 6445.1732

Epoch 00067: loss did not improve from 6192.58910
Epoch 68/2000
 - 33s - loss: 6029.1855 - val_loss: 8908.4464

Epoch 00068: loss improved from 6192.58910 to 6029.18553, saving model to ./weights/_weights.h5
Epoch 69/2000
 - 33s - loss: 6164.9539 - val_loss: 13667.6589

Epoch 00069: loss did not improve from 6029.18553
Epoch 70/2000
 - 33s - loss: 6180.1175 - val_loss: 6418.9107

Epoch 00070: loss did not improve from 6029.18553
Epoch 71/2000
 - 33s - loss: 6047.6794 - val_loss: 7501.5863

Epoch 00071: loss did not improve from 6029.18553
Epoch 72/2000
 - 33s - loss: 6149.7112 - val_loss: 8253.2019

Epoch 00072: loss did not improve from 6029.18553
Epoch 73/2000
 - 33s - loss: 5945.5554 - val_loss: 7701.4413

Epoch 00073: loss improved from 6029.18553 to 5945.55539, saving model to ./weights/_weights.h5
Epoch 74/2000
 - 32s - loss: 6048.3322 - val_loss: 7103.5511

Epoch 00074: loss did not improve from 5945.55539
Epoch 75/2000
 - 35s - loss: 6057.3996 - val_loss: 8427.9174

Epoch 00075: loss did not improve from 5945.55539
Epoch 76/2000
 - 36s - loss: 5983.9545 - val_loss: 11779.7690

Epoch 00076: loss did not improve from 5945.55539
Epoch 77/2000
 - 36s - loss: 6037.4949 - val_loss: 34229.5265

Epoch 00077: loss did not improve from 5945.55539
Epoch 78/2000
 - 36s - loss: 5908.9334 - val_loss: 11830.8609

Epoch 00078: loss improved from 5945.55539 to 5908.93338, saving model to ./weights/_weights.h5
Epoch 79/2000
 - 36s - loss: 5852.8124 - val_loss: 6595.8706

Epoch 00079: loss improved from 5908.93338 to 5852.81240, saving model to ./weights/_weights.h5
Epoch 80/2000
 - 36s - loss: 5841.4746 - val_loss: 6620.7335

Epoch 00080: loss improved from 5852.81240 to 5841.47461, saving model to ./weights/_weights.h5
Epoch 81/2000
 - 36s - loss: 6068.5406 - val_loss: 18819.9775

Epoch 00081: loss did not improve from 5841.47461
Epoch 82/2000
 - 36s - loss: 5805.9399 - val_loss: 7301.9715

Epoch 00082: loss improved from 5841.47461 to 5805.93985, saving model to ./weights/_weights.h5
Epoch 83/2000
 - 36s - loss: 5916.0811 - val_loss: 19469.5396

Epoch 00083: loss did not improve from 5805.93985
Epoch 84/2000
 - 36s - loss: 5978.9411 - val_loss: 6303.6546

Epoch 00084: loss did not improve from 5805.93985
Epoch 85/2000
 - 36s - loss: 5821.3920 - val_loss: 6391.0015

Epoch 00085: loss did not improve from 5805.93985
Epoch 86/2000
 - 36s - loss: 5739.1490 - val_loss: 8303.6025

Epoch 00086: loss improved from 5805.93985 to 5739.14902, saving model to ./weights/_weights.h5
Epoch 87/2000
 - 36s - loss: 5776.7393 - val_loss: 6742.9846

Epoch 00087: loss did not improve from 5739.14902
Epoch 88/2000
 - 36s - loss: 5660.8629 - val_loss: 11780.5395

Epoch 00088: loss improved from 5739.14902 to 5660.86295, saving model to ./weights/_weights.h5
Epoch 89/2000
 - 36s - loss: 5906.4334 - val_loss: 6965.0794

Epoch 00089: loss did not improve from 5660.86295
Epoch 90/2000
 - 36s - loss: 5771.5303 - val_loss: 12472.8961

Epoch 00090: loss did not improve from 5660.86295
Epoch 91/2000
 - 36s - loss: 5718.8687 - val_loss: 10464.7416

Epoch 00091: loss did not improve from 5660.86295
Epoch 92/2000
 - 37s - loss: 5764.5926 - val_loss: 6283.2682

Epoch 00092: loss did not improve from 5660.86295
Epoch 93/2000
 - 35s - loss: 5735.4462 - val_loss: 7321.8760

Epoch 00093: loss did not improve from 5660.86295
Epoch 94/2000
 - 35s - loss: 5647.7227 - val_loss: 16557.2226

Epoch 00094: loss improved from 5660.86295 to 5647.72272, saving model to ./weights/_weights.h5
Epoch 95/2000
 - 35s - loss: 6040.1558 - val_loss: 6564.4446

Epoch 00095: loss did not improve from 5647.72272
Epoch 96/2000
 - 35s - loss: 5541.1869 - val_loss: 9526.1074

Epoch 00096: loss improved from 5647.72272 to 5541.18689, saving model to ./weights/_weights.h5
Epoch 97/2000
 - 35s - loss: 5665.1766 - val_loss: 6821.8149

Epoch 00097: loss did not improve from 5541.18689
Epoch 98/2000
 - 36s - loss: 5624.4978 - val_loss: 6580.0102

Epoch 00098: loss did not improve from 5541.18689
Epoch 99/2000
 - 35s - loss: 5566.3294 - val_loss: 7447.8080

Epoch 00099: loss did not improve from 5541.18689
Epoch 100/2000
 - 35s - loss: 5628.4510 - val_loss: 5856.6319

Epoch 00100: loss did not improve from 5541.18689
Epoch 101/2000
 - 35s - loss: 5538.6996 - val_loss: 6064.8760

Epoch 00101: loss improved from 5541.18689 to 5538.69957, saving model to ./weights/_weights.h5
Epoch 102/2000
 - 35s - loss: 5721.9802 - val_loss: 6834.2936

Epoch 00102: loss did not improve from 5538.69957
Epoch 103/2000
 - 35s - loss: 5493.4394 - val_loss: 9735.2200

Epoch 00103: loss improved from 5538.69957 to 5493.43944, saving model to ./weights/_weights.h5
Epoch 104/2000
 - 35s - loss: 5455.0308 - val_loss: 6392.0455

Epoch 00104: loss improved from 5493.43944 to 5455.03082, saving model to ./weights/_weights.h5
Epoch 105/2000
 - 35s - loss: 5716.4282 - val_loss: 8466.8198

Epoch 00105: loss did not improve from 5455.03082
Epoch 106/2000
 - 35s - loss: 5554.4659 - val_loss: 7101.2138

Epoch 00106: loss did not improve from 5455.03082
Epoch 107/2000
 - 35s - loss: 5464.7670 - val_loss: 6953.1618

Epoch 00107: loss did not improve from 5455.03082
Epoch 108/2000
 - 35s - loss: 5416.6884 - val_loss: 8667.2719

Epoch 00108: loss improved from 5455.03082 to 5416.68840, saving model to ./weights/_weights.h5
Epoch 109/2000
 - 32s - loss: 5443.7900 - val_loss: 5981.2476

Epoch 00109: loss did not improve from 5416.68840
Epoch 110/2000
 - 32s - loss: 5347.0961 - val_loss: 12166.6406

Epoch 00110: loss improved from 5416.68840 to 5347.09608, saving model to ./weights/_weights.h5
Epoch 111/2000
 - 32s - loss: 5424.2880 - val_loss: 6002.0417

Epoch 00111: loss did not improve from 5347.09608
Epoch 112/2000
 - 32s - loss: 5409.8254 - val_loss: 6435.3524

Epoch 00112: loss did not improve from 5347.09608
Epoch 113/2000
 - 32s - loss: 5349.2149 - val_loss: 9462.3496

Epoch 00113: loss did not improve from 5347.09608
Epoch 114/2000
 - 33s - loss: 5538.2450 - val_loss: 8054.4161

Epoch 00114: loss did not improve from 5347.09608
Epoch 115/2000
 - 33s - loss: 5459.8657 - val_loss: 6292.6885

Epoch 00115: loss did not improve from 5347.09608
Epoch 116/2000
 - 33s - loss: 5384.5391 - val_loss: 16303.0336

Epoch 00116: loss did not improve from 5347.09608
Epoch 117/2000
 - 32s - loss: 5262.5945 - val_loss: 18036.7597

Epoch 00117: loss improved from 5347.09608 to 5262.59447, saving model to ./weights/_weights.h5
Epoch 118/2000
 - 33s - loss: 5310.7727 - val_loss: 15507.1599

Epoch 00118: loss did not improve from 5262.59447
Epoch 119/2000
 - 32s - loss: 5523.7391 - val_loss: 10747.9461

Epoch 00119: loss did not improve from 5262.59447
Epoch 120/2000
 - 33s - loss: 5284.6041 - val_loss: 6845.2283

Epoch 00120: loss did not improve from 5262.59447
Epoch 121/2000
 - 32s - loss: 5259.4847 - val_loss: 7029.2220

Epoch 00121: loss improved from 5262.59447 to 5259.48465, saving model to ./weights/_weights.h5
Epoch 122/2000
 - 32s - loss: 5226.6961 - val_loss: 17991.2325

Epoch 00122: loss improved from 5259.48465 to 5226.69611, saving model to ./weights/_weights.h5
Epoch 123/2000
 - 33s - loss: 5264.8799 - val_loss: 5814.1167

Epoch 00123: loss did not improve from 5226.69611
Epoch 124/2000
 - 32s - loss: 5278.9715 - val_loss: 8487.4040

Epoch 00124: loss did not improve from 5226.69611
Epoch 125/2000
 - 33s - loss: 5245.3724 - val_loss: 22188.4941

Epoch 00125: loss did not improve from 5226.69611
Epoch 126/2000
 - 32s - loss: 5262.8557 - val_loss: 6441.1238

Epoch 00126: loss did not improve from 5226.69611
Epoch 127/2000
 - 33s - loss: 5262.0738 - val_loss: 6218.0472

Epoch 00127: loss did not improve from 5226.69611
Epoch 128/2000
 - 33s - loss: 5203.5782 - val_loss: 6259.1248

Epoch 00128: loss improved from 5226.69611 to 5203.57816, saving model to ./weights/_weights.h5
Epoch 129/2000
 - 34s - loss: 5204.5935 - val_loss: 24064.3719

Epoch 00129: loss did not improve from 5203.57816
Epoch 130/2000
 - 34s - loss: 5840.9478 - val_loss: 6412.9889

Epoch 00130: loss did not improve from 5203.57816
Epoch 131/2000
 - 34s - loss: 5267.2814 - val_loss: 6387.7668

Epoch 00131: loss did not improve from 5203.57816
Epoch 132/2000
 - 34s - loss: 5274.8075 - val_loss: 6971.7965

Epoch 00132: loss did not improve from 5203.57816
Epoch 133/2000
 - 34s - loss: 5212.6954 - val_loss: 6406.1545

Epoch 00133: loss did not improve from 5203.57816
Epoch 134/2000
 - 34s - loss: 5081.7165 - val_loss: 6127.4852

Epoch 00134: loss improved from 5203.57816 to 5081.71650, saving model to ./weights/_weights.h5
Epoch 135/2000
 - 33s - loss: 5022.4369 - val_loss: 5686.4525

Epoch 00135: loss improved from 5081.71650 to 5022.43689, saving model to ./weights/_weights.h5
Epoch 136/2000
 - 34s - loss: 5160.6613 - val_loss: 14414.2918

Epoch 00136: loss did not improve from 5022.43689
Epoch 137/2000
 - 33s - loss: 5180.1368 - val_loss: 5503.6935

Epoch 00137: loss did not improve from 5022.43689
Epoch 138/2000
 - 34s - loss: 5153.4043 - val_loss: 6225.6497

Epoch 00138: loss did not improve from 5022.43689
Epoch 139/2000
 - 34s - loss: 5232.6078 - val_loss: 7567.0425

Epoch 00139: loss did not improve from 5022.43689
Epoch 140/2000
 - 34s - loss: 5048.4917 - val_loss: 9134.5230

Epoch 00140: loss did not improve from 5022.43689
Epoch 141/2000
 - 33s - loss: 5076.3052 - val_loss: 5465.4678

Epoch 00141: loss did not improve from 5022.43689
Epoch 142/2000
 - 34s - loss: 5109.4246 - val_loss: 8278.9334

Epoch 00142: loss did not improve from 5022.43689
Epoch 143/2000
 - 34s - loss: 5157.4707 - val_loss: 6776.7604

Epoch 00143: loss did not improve from 5022.43689
Epoch 144/2000
 - 33s - loss: 5204.6027 - val_loss: 9219.7737

Epoch 00144: loss did not improve from 5022.43689
Epoch 145/2000
 - 34s - loss: 5039.5026 - val_loss: 6135.6255

Epoch 00145: loss did not improve from 5022.43689
Epoch 146/2000
 - 33s - loss: 5109.0084 - val_loss: 9082.3063

Epoch 00146: loss did not improve from 5022.43689
Epoch 147/2000
 - 33s - loss: 5216.9699 - val_loss: 9866.8079

Epoch 00147: loss did not improve from 5022.43689
Epoch 148/2000
 - 33s - loss: 5128.5583 - val_loss: 5731.3645

Epoch 00148: loss did not improve from 5022.43689
Epoch 149/2000
 - 33s - loss: 4987.8296 - val_loss: 9252.1060

Epoch 00149: loss improved from 5022.43689 to 4987.82958, saving model to ./weights/_weights.h5
Epoch 150/2000
 - 33s - loss: 5139.0053 - val_loss: 16870.4223

Epoch 00150: loss did not improve from 4987.82958
Epoch 151/2000
 - 33s - loss: 5060.0565 - val_loss: 12288.8792

Epoch 00151: loss did not improve from 4987.82958
Epoch 152/2000
 - 34s - loss: 4991.4970 - val_loss: 5546.0091

Epoch 00152: loss did not improve from 4987.82958
Epoch 153/2000
 - 33s - loss: 4997.9831 - val_loss: 24970.1186

Epoch 00153: loss did not improve from 4987.82958
Epoch 154/2000
 - 33s - loss: 5042.6057 - val_loss: 5506.9532

Epoch 00154: loss did not improve from 4987.82958
Epoch 155/2000
 - 33s - loss: 4876.8296 - val_loss: 37123.5981

Epoch 00155: loss improved from 4987.82958 to 4876.82958, saving model to ./weights/_weights.h5
Epoch 156/2000
 - 33s - loss: 5034.6571 - val_loss: 5529.0481

Epoch 00156: loss did not improve from 4876.82958
Epoch 157/2000
 - 33s - loss: 4874.9192 - val_loss: 15229.9252

Epoch 00157: loss improved from 4876.82958 to 4874.91924, saving model to ./weights/_weights.h5
Epoch 158/2000
 - 33s - loss: 4932.8601 - val_loss: 19530.8896

Epoch 00158: loss did not improve from 4874.91924
Epoch 159/2000
 - 33s - loss: 4935.0321 - val_loss: 8099.7623

Epoch 00159: loss did not improve from 4874.91924
Epoch 160/2000
 - 33s - loss: 4940.0901 - val_loss: 5726.6340

Epoch 00160: loss did not improve from 4874.91924
Epoch 161/2000
 - 34s - loss: 4989.4966 - val_loss: 5874.8279

Epoch 00161: loss did not improve from 4874.91924
Epoch 162/2000
 - 33s - loss: 6293.0514 - val_loss: 17601.6048

Epoch 00162: loss did not improve from 4874.91924
Epoch 163/2000
 - 36s - loss: 4984.6048 - val_loss: 6508.9879

Epoch 00163: loss did not improve from 4874.91924
Epoch 164/2000
 - 37s - loss: 5076.0654 - val_loss: 6032.8026

Epoch 00164: loss did not improve from 4874.91924
Epoch 165/2000
 - 37s - loss: 5003.6114 - val_loss: 6315.9820

Epoch 00165: loss did not improve from 4874.91924
Epoch 166/2000
 - 37s - loss: 4880.0634 - val_loss: 6495.8801

Epoch 00166: loss did not improve from 4874.91924
Epoch 167/2000
 - 37s - loss: 4956.1460 - val_loss: 6079.4047

Epoch 00167: loss did not improve from 4874.91924
Epoch 168/2000
 - 38s - loss: 4946.9768 - val_loss: 5102.1171

Epoch 00168: loss did not improve from 4874.91924
Epoch 169/2000
 - 37s - loss: 4940.7314 - val_loss: 7130.9646

Epoch 00169: loss did not improve from 4874.91924
Epoch 170/2000
 - 37s - loss: 4974.2517 - val_loss: 5472.0560

Epoch 00170: loss did not improve from 4874.91924
Epoch 171/2000
 - 37s - loss: 4807.4651 - val_loss: 5232.6234

Epoch 00171: loss improved from 4874.91924 to 4807.46506, saving model to ./weights/_weights.h5
Epoch 172/2000
 - 37s - loss: 4862.8131 - val_loss: 6578.2037

Epoch 00172: loss did not improve from 4807.46506
Epoch 173/2000
 - 37s - loss: 4910.9414 - val_loss: 7347.2357

Epoch 00173: loss did not improve from 4807.46506
Epoch 174/2000
 - 36s - loss: 4942.6168 - val_loss: 25015.5102

Epoch 00174: loss did not improve from 4807.46506
Epoch 175/2000
 - 37s - loss: 4983.2100 - val_loss: 24113.5626

Epoch 00175: loss did not improve from 4807.46506
Epoch 176/2000
 - 37s - loss: 4837.6407 - val_loss: 6327.5316

Epoch 00176: loss did not improve from 4807.46506
Epoch 177/2000
 - 37s - loss: 4865.5723 - val_loss: 7723.1801

Epoch 00177: loss did not improve from 4807.46506
Epoch 178/2000
 - 37s - loss: 4762.2401 - val_loss: 5383.7040

Epoch 00178: loss improved from 4807.46506 to 4762.24011, saving model to ./weights/_weights.h5
Epoch 179/2000
 - 35s - loss: 4873.1007 - val_loss: 9308.7831

Epoch 00179: loss did not improve from 4762.24011
Epoch 180/2000
 - 33s - loss: 4777.7909 - val_loss: 5744.8380

Epoch 00180: loss did not improve from 4762.24011
Epoch 181/2000
 - 33s - loss: 4849.3550 - val_loss: 6081.5815

Epoch 00181: loss did not improve from 4762.24011
Epoch 182/2000
 - 33s - loss: 4778.5283 - val_loss: 7542.0387

Epoch 00182: loss did not improve from 4762.24011
Epoch 183/2000
 - 33s - loss: 4831.1172 - val_loss: 5536.4463

Epoch 00183: loss did not improve from 4762.24011
Epoch 184/2000
 - 33s - loss: 4800.1169 - val_loss: 5789.6399

Epoch 00184: loss did not improve from 4762.24011
Epoch 185/2000
 - 33s - loss: 4755.5218 - val_loss: 5349.2980

Epoch 00185: loss improved from 4762.24011 to 4755.52177, saving model to ./weights/_weights.h5
Epoch 186/2000
 - 33s - loss: 4676.1503 - val_loss: 5349.0062

Epoch 00186: loss improved from 4755.52177 to 4676.15032, saving model to ./weights/_weights.h5
Epoch 187/2000
 - 33s - loss: 4842.9877 - val_loss: 9204.2355

Epoch 00187: loss did not improve from 4676.15032
Epoch 188/2000
 - 33s - loss: 4753.5379 - val_loss: 5508.9037

Epoch 00188: loss did not improve from 4676.15032
Epoch 189/2000
 - 33s - loss: 4717.2681 - val_loss: 10197.0059

Epoch 00189: loss did not improve from 4676.15032
Epoch 190/2000
 - 33s - loss: 4878.7416 - val_loss: 10351.6096

Epoch 00190: loss did not improve from 4676.15032
Epoch 191/2000
 - 33s - loss: 4754.8256 - val_loss: 12329.4705

Epoch 00191: loss did not improve from 4676.15032
Epoch 192/2000
 - 33s - loss: 4754.0444 - val_loss: 5930.3384

Epoch 00192: loss did not improve from 4676.15032
Epoch 193/2000
 - 33s - loss: 4731.4920 - val_loss: 6560.9940

Epoch 00193: loss did not improve from 4676.15032
Epoch 194/2000
 - 33s - loss: 4735.3380 - val_loss: 5957.4389

Epoch 00194: loss did not improve from 4676.15032
Epoch 195/2000
 - 33s - loss: 4662.4810 - val_loss: 4855.8012

Epoch 00195: loss improved from 4676.15032 to 4662.48103, saving model to ./weights/_weights.h5
Epoch 196/2000
 - 33s - loss: 4727.2551 - val_loss: 8534.5701

Epoch 00196: loss did not improve from 4662.48103
Epoch 197/2000
 - 33s - loss: 4704.1500 - val_loss: 6095.4118

Epoch 00197: loss did not improve from 4662.48103
Epoch 198/2000
 - 35s - loss: 4733.3933 - val_loss: 7095.1847

Epoch 00198: loss did not improve from 4662.48103
Epoch 199/2000
 - 35s - loss: 4643.9270 - val_loss: 7370.8298

Epoch 00199: loss improved from 4662.48103 to 4643.92701, saving model to ./weights/_weights.h5
Epoch 200/2000
 - 35s - loss: 4643.3131 - val_loss: 7107.5764

Epoch 00200: loss improved from 4643.92701 to 4643.31308, saving model to ./weights/_weights.h5
Epoch 201/2000
 - 35s - loss: 4691.5973 - val_loss: 11829.1418

Epoch 00201: loss did not improve from 4643.31308
Epoch 202/2000
 - 35s - loss: 4627.7271 - val_loss: 17081.7936

Epoch 00202: loss improved from 4643.31308 to 4627.72707, saving model to ./weights/_weights.h5
Epoch 203/2000
 - 35s - loss: 4638.4565 - val_loss: 6811.5955

Epoch 00203: loss did not improve from 4627.72707
Epoch 204/2000
 - 35s - loss: 4619.9484 - val_loss: 10238.6557

Epoch 00204: loss improved from 4627.72707 to 4619.94836, saving model to ./weights/_weights.h5
Epoch 205/2000
 - 35s - loss: 4610.7545 - val_loss: 9297.1133

Epoch 00205: loss improved from 4619.94836 to 4610.75445, saving model to ./weights/_weights.h5
Epoch 206/2000
 - 35s - loss: 4622.1871 - val_loss: 5198.9226

Epoch 00206: loss did not improve from 4610.75445
Epoch 207/2000
 - 35s - loss: 4663.3183 - val_loss: 7002.9798

Epoch 00207: loss did not improve from 4610.75445
Epoch 208/2000
 - 35s - loss: 4583.5787 - val_loss: 4758.7050

Epoch 00208: loss improved from 4610.75445 to 4583.57870, saving model to ./weights/_weights.h5
Epoch 209/2000
 - 35s - loss: 4706.8506 - val_loss: 5731.4405

Epoch 00209: loss did not improve from 4583.57870
Epoch 210/2000
 - 35s - loss: 4621.2129 - val_loss: 7590.0586

Epoch 00210: loss did not improve from 4583.57870
Epoch 211/2000
 - 35s - loss: 4717.4482 - val_loss: 6130.8292

Epoch 00211: loss did not improve from 4583.57870
Epoch 212/2000
 - 35s - loss: 4656.9337 - val_loss: 4884.9273

Epoch 00212: loss did not improve from 4583.57870
Epoch 213/2000
 - 35s - loss: 4641.6888 - val_loss: 28707.6775

Epoch 00213: loss did not improve from 4583.57870
Epoch 214/2000
 - 34s - loss: 4600.0451 - val_loss: 7920.3971

Epoch 00214: loss did not improve from 4583.57870
Epoch 215/2000
 - 32s - loss: 4751.5550 - val_loss: 6086.3802

Epoch 00215: loss did not improve from 4583.57870
Epoch 216/2000
 - 33s - loss: 4524.3326 - val_loss: 7043.0773

Epoch 00216: loss improved from 4583.57870 to 4524.33256, saving model to ./weights/_weights.h5
Epoch 217/2000
 - 32s - loss: 4583.7775 - val_loss: 18013.1250

Epoch 00217: loss did not improve from 4524.33256
Epoch 218/2000
 - 32s - loss: 4639.8252 - val_loss: 10206.1729

Epoch 00218: loss did not improve from 4524.33256
Epoch 219/2000
 - 32s - loss: 4498.3566 - val_loss: 6130.9261

Epoch 00219: loss improved from 4524.33256 to 4498.35659, saving model to ./weights/_weights.h5
Epoch 220/2000
 - 33s - loss: 4585.9137 - val_loss: 4994.2473

Epoch 00220: loss did not improve from 4498.35659
Epoch 221/2000
 - 32s - loss: 4455.8390 - val_loss: 7812.7427

Epoch 00221: loss improved from 4498.35659 to 4455.83897, saving model to ./weights/_weights.h5
Epoch 222/2000
 - 33s - loss: 4636.7274 - val_loss: 6245.4250

Epoch 00222: loss did not improve from 4455.83897
Epoch 223/2000
 - 32s - loss: 4586.5095 - val_loss: 11632.5607

Epoch 00223: loss did not improve from 4455.83897
Epoch 224/2000
 - 32s - loss: 4606.3916 - val_loss: 7331.2381

Epoch 00224: loss did not improve from 4455.83897
Epoch 225/2000
 - 32s - loss: 4578.3809 - val_loss: 4991.0629

Epoch 00225: loss did not improve from 4455.83897
Epoch 226/2000
 - 32s - loss: 4499.7416 - val_loss: 5016.2686

Epoch 00226: loss did not improve from 4455.83897
Epoch 227/2000
 - 32s - loss: 4646.8205 - val_loss: 4864.1469

Epoch 00227: loss did not improve from 4455.83897
Epoch 228/2000
 - 32s - loss: 5045.1643 - val_loss: 23772.2117

Epoch 00228: loss did not improve from 4455.83897
Epoch 229/2000
 - 32s - loss: 4603.6493 - val_loss: 9147.4006

Epoch 00229: loss did not improve from 4455.83897
Epoch 230/2000
 - 32s - loss: 4703.5597 - val_loss: 19565.4932

Epoch 00230: loss did not improve from 4455.83897
Epoch 231/2000
 - 33s - loss: 4645.6431 - val_loss: 6555.4247

Epoch 00231: loss did not improve from 4455.83897
Epoch 232/2000
 - 32s - loss: 4511.8793 - val_loss: 9770.3112

Epoch 00232: loss did not improve from 4455.83897
Epoch 233/2000
 - 32s - loss: 4506.9941 - val_loss: 5255.0249

Epoch 00233: loss did not improve from 4455.83897
Epoch 234/2000
 - 32s - loss: 4461.1997 - val_loss: 5206.1167

Epoch 00234: loss did not improve from 4455.83897
Epoch 235/2000
 - 32s - loss: 4565.3435 - val_loss: 5436.5030

Epoch 00235: loss did not improve from 4455.83897
Epoch 236/2000
 - 32s - loss: 4550.6210 - val_loss: 7802.4243

Epoch 00236: loss did not improve from 4455.83897
Epoch 237/2000
 - 32s - loss: 4633.9035 - val_loss: 11657.1643

Epoch 00237: loss did not improve from 4455.83897
Epoch 238/2000
 - 32s - loss: 4464.0071 - val_loss: 4974.0584

Epoch 00238: loss did not improve from 4455.83897
Epoch 239/2000
 - 33s - loss: 4550.1466 - val_loss: 4918.9878

Epoch 00239: loss did not improve from 4455.83897
Epoch 240/2000
 - 33s - loss: 4569.9637 - val_loss: 9790.6977

Epoch 00240: loss did not improve from 4455.83897
Epoch 241/2000
 - 33s - loss: 4450.4044 - val_loss: 9240.9644

Epoch 00241: loss improved from 4455.83897 to 4450.40437, saving model to ./weights/_weights.h5
Epoch 242/2000
 - 32s - loss: 4555.0302 - val_loss: 13088.2070

Epoch 00242: loss did not improve from 4450.40437
Epoch 243/2000
 - 33s - loss: 4539.6302 - val_loss: 5284.2761

Epoch 00243: loss did not improve from 4450.40437
Epoch 244/2000
 - 33s - loss: 4514.1122 - val_loss: 6995.1283

Epoch 00244: loss did not improve from 4450.40437
Epoch 245/2000
 - 32s - loss: 4468.4307 - val_loss: 4780.5094

Epoch 00245: loss did not improve from 4450.40437
Epoch 246/2000
 - 33s - loss: 4458.4212 - val_loss: 4995.4469

Epoch 00246: loss did not improve from 4450.40437
Epoch 247/2000
 - 32s - loss: 4490.0853 - val_loss: 10377.7542

Epoch 00247: loss did not improve from 4450.40437
Epoch 248/2000
 - 33s - loss: 4463.9933 - val_loss: 5738.4480

Epoch 00248: loss did not improve from 4450.40437
Epoch 249/2000
 - 32s - loss: 4427.8812 - val_loss: 8296.1189

Epoch 00249: loss improved from 4450.40437 to 4427.88116, saving model to ./weights/_weights.h5
Epoch 250/2000
 - 33s - loss: 4398.2634 - val_loss: 9310.6212

Epoch 00250: loss improved from 4427.88116 to 4398.26337, saving model to ./weights/_weights.h5
Epoch 251/2000
 - 32s - loss: 4462.6011 - val_loss: 16087.8398

Epoch 00251: loss did not improve from 4398.26337
Epoch 252/2000
 - 33s - loss: 4482.2176 - val_loss: 7013.1250

Epoch 00252: loss did not improve from 4398.26337
Epoch 253/2000
 - 32s - loss: 4382.0057 - val_loss: 7717.4841

Epoch 00253: loss improved from 4398.26337 to 4382.00573, saving model to ./weights/_weights.h5
Epoch 254/2000
 - 32s - loss: 4391.3317 - val_loss: 5573.0529

Epoch 00254: loss did not improve from 4382.00573
Epoch 255/2000
 - 32s - loss: 4432.9921 - val_loss: 20111.4361

Epoch 00255: loss did not improve from 4382.00573
Epoch 256/2000
 - 32s - loss: 4470.3194 - val_loss: 8362.5066

Epoch 00256: loss did not improve from 4382.00573
Epoch 257/2000
 - 33s - loss: 4377.1416 - val_loss: 8641.9886

Epoch 00257: loss improved from 4382.00573 to 4377.14155, saving model to ./weights/_weights.h5
Epoch 258/2000
 - 32s - loss: 4464.9577 - val_loss: 5122.3331

Epoch 00258: loss did not improve from 4377.14155
Epoch 259/2000
 - 33s - loss: 4331.8249 - val_loss: 6944.6288

Epoch 00259: loss improved from 4377.14155 to 4331.82493, saving model to ./weights/_weights.h5
Epoch 260/2000
 - 32s - loss: 4408.2959 - val_loss: 4977.9310

Epoch 00260: loss did not improve from 4331.82493
Epoch 261/2000
 - 32s - loss: 4358.4160 - val_loss: 13515.9097

Epoch 00261: loss did not improve from 4331.82493
Epoch 262/2000
 - 32s - loss: 4647.6806 - val_loss: 5933.1649

Epoch 00262: loss did not improve from 4331.82493
Epoch 263/2000
 - 32s - loss: 4472.6535 - val_loss: 4916.4841

Epoch 00263: loss did not improve from 4331.82493
Epoch 264/2000
 - 32s - loss: 4338.9561 - val_loss: 11044.6129

Epoch 00264: loss did not improve from 4331.82493
Epoch 265/2000
 - 32s - loss: 4340.1197 - val_loss: 5385.4606

Epoch 00265: loss did not improve from 4331.82493
Epoch 266/2000
 - 32s - loss: 4363.0752 - val_loss: 5963.3790

Epoch 00266: loss did not improve from 4331.82493
Epoch 267/2000
 - 32s - loss: 4343.3840 - val_loss: 7220.6635

Epoch 00267: loss did not improve from 4331.82493
Epoch 268/2000
 - 33s - loss: 4293.3295 - val_loss: 5582.4887

Epoch 00268: loss improved from 4331.82493 to 4293.32947, saving model to ./weights/_weights.h5
Epoch 269/2000
 - 32s - loss: 4351.9435 - val_loss: 7250.6550

Epoch 00269: loss did not improve from 4293.32947
Epoch 270/2000
 - 33s - loss: 4212.0686 - val_loss: 5461.9759

Epoch 00270: loss improved from 4293.32947 to 4212.06858, saving model to ./weights/_weights.h5
Epoch 271/2000
 - 32s - loss: 4370.8701 - val_loss: 5031.2101

Epoch 00271: loss did not improve from 4212.06858
Epoch 272/2000
 - 33s - loss: 4271.0071 - val_loss: 5494.5836

Epoch 00272: loss did not improve from 4212.06858
Epoch 273/2000
 - 32s - loss: 4277.1877 - val_loss: 5944.6391

Epoch 00273: loss did not improve from 4212.06858
Epoch 274/2000
 - 32s - loss: 4422.1040 - val_loss: 8828.5470

Epoch 00274: loss did not improve from 4212.06858
Epoch 275/2000
 - 32s - loss: 4376.8436 - val_loss: 8384.5577

Epoch 00275: loss did not improve from 4212.06858
Epoch 276/2000
 - 33s - loss: 4181.3377 - val_loss: 4924.3123

Epoch 00276: loss improved from 4212.06858 to 4181.33775, saving model to ./weights/_weights.h5
Epoch 277/2000
 - 33s - loss: 4230.1588 - val_loss: 6423.9079

Epoch 00277: loss did not improve from 4181.33775
Epoch 278/2000
 - 33s - loss: 4221.2313 - val_loss: 5027.8005

Epoch 00278: loss did not improve from 4181.33775
Epoch 279/2000
 - 32s - loss: 4234.1967 - val_loss: 14615.6101

Epoch 00279: loss did not improve from 4181.33775
Epoch 280/2000
 - 32s - loss: 4218.3885 - val_loss: 10342.5665

Epoch 00280: loss did not improve from 4181.33775
Epoch 281/2000
 - 32s - loss: 4271.2357 - val_loss: 7984.8450

Epoch 00281: loss did not improve from 4181.33775
Epoch 282/2000
 - 32s - loss: 4335.7149 - val_loss: 5625.1533

Epoch 00282: loss did not improve from 4181.33775
Epoch 283/2000
 - 32s - loss: 4250.4134 - val_loss: 4638.0747

Epoch 00283: loss did not improve from 4181.33775
Epoch 284/2000
 - 32s - loss: 4205.3723 - val_loss: 6133.4135

Epoch 00284: loss did not improve from 4181.33775
Epoch 285/2000
 - 33s - loss: 4278.1407 - val_loss: 6603.3226

Epoch 00285: loss did not improve from 4181.33775
Epoch 286/2000
 - 32s - loss: 4267.1528 - val_loss: 4803.1398

Epoch 00286: loss did not improve from 4181.33775
Epoch 287/2000
 - 33s - loss: 4111.1476 - val_loss: 7311.2454

Epoch 00287: loss improved from 4181.33775 to 4111.14762, saving model to ./weights/_weights.h5
Epoch 288/2000
 - 32s - loss: 4233.8632 - val_loss: 5130.8756

Epoch 00288: loss did not improve from 4111.14762
Epoch 289/2000
 - 32s - loss: 4282.6689 - val_loss: 5345.9340

Epoch 00289: loss did not improve from 4111.14762
Epoch 290/2000
 - 32s - loss: 4265.5863 - val_loss: 6927.1615

Epoch 00290: loss did not improve from 4111.14762
Epoch 291/2000
 - 32s - loss: 4258.7993 - val_loss: 4975.6811

Epoch 00291: loss did not improve from 4111.14762
Epoch 292/2000
 - 32s - loss: 4279.1349 - val_loss: 7516.3395

Epoch 00292: loss did not improve from 4111.14762
Epoch 293/2000
 - 32s - loss: 4239.7373 - val_loss: 6544.4724

Epoch 00293: loss did not improve from 4111.14762
Epoch 294/2000
 - 32s - loss: 4157.1845 - val_loss: 6980.0026

Epoch 00294: loss did not improve from 4111.14762
Epoch 295/2000
 - 32s - loss: 4266.1770 - val_loss: 10222.4768

Epoch 00295: loss did not improve from 4111.14762
Epoch 296/2000
 - 33s - loss: 4222.0945 - val_loss: 6797.9698

Epoch 00296: loss did not improve from 4111.14762
Epoch 297/2000
 - 32s - loss: 4157.0688 - val_loss: 8380.6045

Epoch 00297: loss did not improve from 4111.14762
Epoch 298/2000
 - 32s - loss: 4250.0832 - val_loss: 6815.7947

Epoch 00298: loss did not improve from 4111.14762
Epoch 299/2000
 - 32s - loss: 4224.8800 - val_loss: 18099.6611

Epoch 00299: loss did not improve from 4111.14762
Epoch 300/2000
 - 32s - loss: 4163.3091 - val_loss: 11638.1265

Epoch 00300: loss did not improve from 4111.14762
Epoch 301/2000
 - 33s - loss: 4274.4500 - val_loss: 9204.5918

Epoch 00301: loss did not improve from 4111.14762
Epoch 302/2000
 - 32s - loss: 4311.0280 - val_loss: 5064.4416

Epoch 00302: loss did not improve from 4111.14762
Epoch 303/2000
 - 32s - loss: 4141.0183 - val_loss: 5578.8664

Epoch 00303: loss did not improve from 4111.14762
Epoch 304/2000
 - 32s - loss: 4196.0178 - val_loss: 4760.3868

Epoch 00304: loss did not improve from 4111.14762
Epoch 305/2000
 - 33s - loss: 4290.9798 - val_loss: 5338.9609

Epoch 00305: loss did not improve from 4111.14762
Epoch 306/2000
 - 32s - loss: 4116.5366 - val_loss: 9004.6456

Epoch 00306: loss did not improve from 4111.14762
Epoch 307/2000
 - 33s - loss: 4180.9692 - val_loss: 5507.4577

Epoch 00307: loss did not improve from 4111.14762
Epoch 308/2000
 - 32s - loss: 4088.6433 - val_loss: 10869.2886

Epoch 00308: loss improved from 4111.14762 to 4088.64330, saving model to ./weights/_weights.h5
Epoch 309/2000
 - 32s - loss: 4132.2855 - val_loss: 7639.5624

Epoch 00309: loss did not improve from 4088.64330
Epoch 310/2000
 - 32s - loss: 4167.5629 - val_loss: 6188.8295

Epoch 00310: loss did not improve from 4088.64330
Epoch 311/2000
 - 32s - loss: 4152.0980 - val_loss: 6473.8834

Epoch 00311: loss did not improve from 4088.64330
Epoch 312/2000
 - 32s - loss: 4243.4653 - val_loss: 8165.7984

Epoch 00312: loss did not improve from 4088.64330
Epoch 313/2000
 - 33s - loss: 4102.9006 - val_loss: 4891.7453

Epoch 00313: loss did not improve from 4088.64330
Epoch 314/2000
 - 33s - loss: 4164.1739 - val_loss: 5400.6778

Epoch 00314: loss did not improve from 4088.64330
Epoch 315/2000
 - 33s - loss: 4118.3762 - val_loss: 12506.3154

Epoch 00315: loss did not improve from 4088.64330
Epoch 316/2000
 - 32s - loss: 4155.7509 - val_loss: 13993.7254

Epoch 00316: loss did not improve from 4088.64330
Epoch 317/2000
 - 32s - loss: 4137.9849 - val_loss: 6811.1956

Epoch 00317: loss did not improve from 4088.64330
Epoch 318/2000
 - 32s - loss: 4102.7896 - val_loss: 5203.0794

Epoch 00318: loss did not improve from 4088.64330
Epoch 319/2000
 - 32s - loss: 4193.1222 - val_loss: 10656.0138

Epoch 00319: loss did not improve from 4088.64330
Epoch 320/2000
 - 32s - loss: 4207.5900 - val_loss: 8309.6042

Epoch 00320: loss did not improve from 4088.64330
Epoch 321/2000
 - 32s - loss: 4178.7290 - val_loss: 5244.5360

Epoch 00321: loss did not improve from 4088.64330
Epoch 322/2000
 - 33s - loss: 4169.5220 - val_loss: 16182.5677

Epoch 00322: loss did not improve from 4088.64330
Epoch 323/2000
 - 32s - loss: 4252.8377 - val_loss: 9593.4226

Epoch 00323: loss did not improve from 4088.64330
Epoch 324/2000
 - 33s - loss: 4158.9804 - val_loss: 9203.7560

Epoch 00324: loss did not improve from 4088.64330
Epoch 325/2000
 - 32s - loss: 4037.2080 - val_loss: 13427.4542

Epoch 00325: loss improved from 4088.64330 to 4037.20796, saving model to ./weights/_weights.h5
Epoch 326/2000
 - 32s - loss: 4099.6055 - val_loss: 10652.9526

Epoch 00326: loss did not improve from 4037.20796
Epoch 327/2000
 - 32s - loss: 4021.9207 - val_loss: 5246.1760

Epoch 00327: loss improved from 4037.20796 to 4021.92067, saving model to ./weights/_weights.h5
Epoch 328/2000
 - 32s - loss: 4172.3419 - val_loss: 8903.8318

Epoch 00328: loss did not improve from 4021.92067
Epoch 329/2000
 - 32s - loss: 4158.8018 - val_loss: 7646.5302

Epoch 00329: loss did not improve from 4021.92067
Epoch 330/2000
 - 32s - loss: 4197.9476 - val_loss: 14411.4218

Epoch 00330: loss did not improve from 4021.92067
Epoch 331/2000
 - 33s - loss: 4164.4412 - val_loss: 5644.1746

Epoch 00331: loss did not improve from 4021.92067
Epoch 332/2000
 - 32s - loss: 4107.3845 - val_loss: 21436.2172

Epoch 00332: loss did not improve from 4021.92067
Epoch 333/2000
 - 33s - loss: 4083.2210 - val_loss: 6595.8933

Epoch 00333: loss did not improve from 4021.92067
Epoch 334/2000
 - 32s - loss: 4070.3373 - val_loss: 5299.0409

Epoch 00334: loss did not improve from 4021.92067
Epoch 335/2000
 - 33s - loss: 4025.7873 - val_loss: 6682.4774

Epoch 00335: loss did not improve from 4021.92067
Epoch 336/2000
 - 32s - loss: 3987.6325 - val_loss: 8583.9762

Epoch 00336: loss improved from 4021.92067 to 3987.63246, saving model to ./weights/_weights.h5
Epoch 337/2000
 - 32s - loss: 4001.9119 - val_loss: 5065.2826

Epoch 00337: loss did not improve from 3987.63246
Epoch 338/2000
 - 32s - loss: 4008.8958 - val_loss: 29072.2679

Epoch 00338: loss did not improve from 3987.63246
Epoch 339/2000
 - 32s - loss: 4035.2806 - val_loss: 9538.3646

Epoch 00339: loss did not improve from 3987.63246
Epoch 340/2000
 - 32s - loss: 4053.7125 - val_loss: 6045.0853

Epoch 00340: loss did not improve from 3987.63246
Epoch 341/2000
 - 33s - loss: 4003.4943 - val_loss: 4846.0909

Epoch 00341: loss did not improve from 3987.63246
Epoch 342/2000
 - 33s - loss: 3974.5680 - val_loss: 4707.7021

Epoch 00342: loss improved from 3987.63246 to 3974.56802, saving model to ./weights/_weights.h5
Epoch 343/2000
 - 33s - loss: 3943.0517 - val_loss: 11329.4570

Epoch 00343: loss improved from 3974.56802 to 3943.05169, saving model to ./weights/_weights.h5
Epoch 344/2000
 - 32s - loss: 4077.0614 - val_loss: 23849.6921

Epoch 00344: loss did not improve from 3943.05169
Epoch 345/2000
 - 32s - loss: 4217.7323 - val_loss: 4634.0959

Epoch 00345: loss did not improve from 3943.05169
Epoch 346/2000
 - 32s - loss: 4019.2370 - val_loss: 4583.1798

Epoch 00346: loss did not improve from 3943.05169
Epoch 347/2000
 - 32s - loss: 3969.0874 - val_loss: 5366.5150

Epoch 00347: loss did not improve from 3943.05169
Epoch 348/2000
 - 32s - loss: 3976.3004 - val_loss: 5387.2438

Epoch 00348: loss did not improve from 3943.05169
Epoch 349/2000
 - 32s - loss: 3953.6429 - val_loss: 8404.8845

Epoch 00349: loss did not improve from 3943.05169
Epoch 350/2000
 - 33s - loss: 4085.2200 - val_loss: 11231.5859

Epoch 00350: loss did not improve from 3943.05169
Epoch 351/2000
 - 32s - loss: 4035.8207 - val_loss: 7450.8699

Epoch 00351: loss did not improve from 3943.05169
Epoch 352/2000
 - 33s - loss: 4098.9167 - val_loss: 6409.1405

Epoch 00352: loss did not improve from 3943.05169
Epoch 353/2000
 - 32s - loss: 3954.6349 - val_loss: 7277.2243

Epoch 00353: loss did not improve from 3943.05169
Epoch 354/2000
 - 32s - loss: 3953.4910 - val_loss: 6331.1890

Epoch 00354: loss did not improve from 3943.05169
Epoch 355/2000
 - 32s - loss: 3981.3688 - val_loss: 7742.4406

Epoch 00355: loss did not improve from 3943.05169
Epoch 356/2000
 - 33s - loss: 4048.4681 - val_loss: 4511.9823

Epoch 00356: loss did not improve from 3943.05169
Epoch 357/2000
 - 32s - loss: 3921.9391 - val_loss: 5052.8354

Epoch 00357: loss improved from 3943.05169 to 3921.93906, saving model to ./weights/_weights.h5
Epoch 358/2000
 - 32s - loss: 3960.4114 - val_loss: 6346.3547

Epoch 00358: loss did not improve from 3921.93906
Epoch 359/2000
 - 33s - loss: 4015.7382 - val_loss: 5715.7981

Epoch 00359: loss did not improve from 3921.93906
Epoch 360/2000
 - 32s - loss: 3934.3822 - val_loss: 7890.0841

Epoch 00360: loss did not improve from 3921.93906
Epoch 361/2000
 - 33s - loss: 3959.1007 - val_loss: 15586.2345

Epoch 00361: loss did not improve from 3921.93906
Epoch 362/2000
 - 32s - loss: 4088.8634 - val_loss: 6241.2935

Epoch 00362: loss did not improve from 3921.93906
Epoch 363/2000
 - 33s - loss: 4033.2449 - val_loss: 13621.9666

Epoch 00363: loss did not improve from 3921.93906
Epoch 364/2000
 - 32s - loss: 3921.9185 - val_loss: 8224.4583

Epoch 00364: loss improved from 3921.93906 to 3921.91846, saving model to ./weights/_weights.h5
Epoch 365/2000
 - 32s - loss: 3921.0746 - val_loss: 4707.3267

Epoch 00365: loss improved from 3921.91846 to 3921.07464, saving model to ./weights/_weights.h5
Epoch 366/2000
 - 32s - loss: 3990.3317 - val_loss: 5043.7492

Epoch 00366: loss did not improve from 3921.07464
Epoch 367/2000
 - 32s - loss: 3923.5275 - val_loss: 23811.1113

Epoch 00367: loss did not improve from 3921.07464
Epoch 368/2000
 - 32s - loss: 3982.4229 - val_loss: 5882.6765

Epoch 00368: loss did not improve from 3921.07464
Epoch 369/2000
 - 32s - loss: 3938.7138 - val_loss: 4861.6613

Epoch 00369: loss did not improve from 3921.07464
Epoch 370/2000
 - 33s - loss: 3846.7551 - val_loss: 11005.8082

Epoch 00370: loss improved from 3921.07464 to 3846.75506, saving model to ./weights/_weights.h5
Epoch 371/2000
 - 32s - loss: 3929.3903 - val_loss: 5866.0292

Epoch 00371: loss did not improve from 3846.75506
Epoch 372/2000
 - 33s - loss: 3886.6554 - val_loss: 5211.1838

Epoch 00372: loss did not improve from 3846.75506
Epoch 373/2000
 - 32s - loss: 3936.2068 - val_loss: 4967.7226

Epoch 00373: loss did not improve from 3846.75506
Epoch 374/2000
 - 32s - loss: 3963.6982 - val_loss: 8933.1836

Epoch 00374: loss did not improve from 3846.75506
Epoch 375/2000
 - 32s - loss: 3869.5479 - val_loss: 5145.7211

Epoch 00375: loss did not improve from 3846.75506
Epoch 376/2000
 - 32s - loss: 3909.3351 - val_loss: 6586.6052

Epoch 00376: loss did not improve from 3846.75506
Epoch 377/2000
 - 32s - loss: 4301.7894 - val_loss: 10555.4838

Epoch 00377: loss did not improve from 3846.75506
Epoch 378/2000
 - 33s - loss: 3907.7415 - val_loss: 7130.9243

Epoch 00378: loss did not improve from 3846.75506
Epoch 379/2000
 - 33s - loss: 4129.8469 - val_loss: 4781.7525

Epoch 00379: loss did not improve from 3846.75506
Epoch 380/2000
 - 33s - loss: 3927.6231 - val_loss: 5934.9082

Epoch 00380: loss did not improve from 3846.75506
Epoch 381/2000
 - 32s - loss: 3929.8779 - val_loss: 9152.8574

Epoch 00381: loss did not improve from 3846.75506
Epoch 382/2000
 - 32s - loss: 3851.5364 - val_loss: 8806.7057

Epoch 00382: loss did not improve from 3846.75506
Epoch 383/2000
 - 32s - loss: 3850.8195 - val_loss: 4918.6231

Epoch 00383: loss did not improve from 3846.75506
Epoch 384/2000
 - 32s - loss: 3774.3580 - val_loss: 6943.6204

Epoch 00384: loss improved from 3846.75506 to 3774.35800, saving model to ./weights/_weights.h5
Epoch 385/2000
 - 32s - loss: 3951.6022 - val_loss: 17251.4162

Epoch 00385: loss did not improve from 3774.35800
Epoch 386/2000
 - 32s - loss: 4010.2922 - val_loss: 5077.7473

Epoch 00386: loss did not improve from 3774.35800
Epoch 387/2000
 - 33s - loss: 3890.3970 - val_loss: 5927.9233

Epoch 00387: loss did not improve from 3774.35800
Epoch 388/2000
 - 32s - loss: 3886.8834 - val_loss: 4615.4791

Epoch 00388: loss did not improve from 3774.35800
Epoch 389/2000
 - 33s - loss: 3847.3400 - val_loss: 10388.3933

Epoch 00389: loss did not improve from 3774.35800
Epoch 390/2000
 - 32s - loss: 3758.9231 - val_loss: 4578.4584

Epoch 00390: loss improved from 3774.35800 to 3758.92308, saving model to ./weights/_weights.h5
Epoch 391/2000
 - 32s - loss: 3818.7924 - val_loss: 4776.3255

Epoch 00391: loss did not improve from 3758.92308
Epoch 392/2000
 - 32s - loss: 3853.5645 - val_loss: 5183.6499

Epoch 00392: loss did not improve from 3758.92308
Epoch 393/2000
 - 32s - loss: 3965.9788 - val_loss: 5257.4444

Epoch 00393: loss did not improve from 3758.92308
Epoch 394/2000
 - 32s - loss: 3912.3057 - val_loss: 5478.9026

Epoch 00394: loss did not improve from 3758.92308
Epoch 395/2000
 - 32s - loss: 3858.7611 - val_loss: 4887.7812

Epoch 00395: loss did not improve from 3758.92308
Epoch 396/2000
 - 33s - loss: 3775.5847 - val_loss: 8330.9447

Epoch 00396: loss did not improve from 3758.92308
Epoch 397/2000
 - 32s - loss: 3831.6260 - val_loss: 14374.6933

Epoch 00397: loss did not improve from 3758.92308
Epoch 398/2000
 - 33s - loss: 3937.5964 - val_loss: 4779.5494

Epoch 00398: loss did not improve from 3758.92308
Epoch 399/2000
 - 32s - loss: 3811.8191 - val_loss: 10006.7905

Epoch 00399: loss did not improve from 3758.92308
Epoch 400/2000
 - 33s - loss: 3841.9315 - val_loss: 4817.3347

Epoch 00400: loss did not improve from 3758.92308
Epoch 401/2000
 - 32s - loss: 3797.2278 - val_loss: 18151.1222

Epoch 00401: loss did not improve from 3758.92308
Epoch 402/2000
 - 32s - loss: 3795.1064 - val_loss: 5546.2382

Epoch 00402: loss did not improve from 3758.92308
Epoch 403/2000
 - 32s - loss: 3932.6136 - val_loss: 4410.5551

Epoch 00403: loss did not improve from 3758.92308
Epoch 404/2000
 - 32s - loss: 3838.9614 - val_loss: 10993.2687

Epoch 00404: loss did not improve from 3758.92308
Epoch 405/2000
 - 32s - loss: 3865.1296 - val_loss: 15598.4028

Epoch 00405: loss did not improve from 3758.92308
Epoch 406/2000
 - 32s - loss: 3779.3961 - val_loss: 6174.3948

Epoch 00406: loss did not improve from 3758.92308
Epoch 407/2000
 - 33s - loss: 3785.1278 - val_loss: 5003.8482

Epoch 00407: loss did not improve from 3758.92308
Epoch 408/2000
 - 32s - loss: 3838.2496 - val_loss: 7080.2152

Epoch 00408: loss did not improve from 3758.92308
Epoch 409/2000
 - 32s - loss: 3772.0482 - val_loss: 5961.1301

Epoch 00409: loss did not improve from 3758.92308
Epoch 410/2000
 - 32s - loss: 3775.2465 - val_loss: 5352.8884

Epoch 00410: loss did not improve from 3758.92308
Epoch 411/2000
 - 33s - loss: 3835.0654 - val_loss: 5658.9989

Epoch 00411: loss did not improve from 3758.92308
Epoch 412/2000
 - 32s - loss: 3858.9685 - val_loss: 7715.1603

Epoch 00412: loss did not improve from 3758.92308
Epoch 413/2000
 - 32s - loss: 3810.6864 - val_loss: 10541.2624

Epoch 00413: loss did not improve from 3758.92308
Epoch 414/2000
 - 32s - loss: 3798.7141 - val_loss: 5537.8822

Epoch 00414: loss did not improve from 3758.92308
Epoch 415/2000
 - 32s - loss: 3970.7708 - val_loss: 8576.3169

Epoch 00415: loss did not improve from 3758.92308
Epoch 416/2000
 - 33s - loss: 3753.7695 - val_loss: 4682.4143

Epoch 00416: loss improved from 3758.92308 to 3753.76945, saving model to ./weights/_weights.h5
Epoch 417/2000
 - 33s - loss: 3796.3941 - val_loss: 5614.8116

Epoch 00417: loss did not improve from 3753.76945
Epoch 418/2000
 - 32s - loss: 3762.8227 - val_loss: 5236.8822

Epoch 00418: loss did not improve from 3753.76945
Epoch 419/2000
 - 32s - loss: 3877.5829 - val_loss: 6402.9523

Epoch 00419: loss did not improve from 3753.76945
Epoch 420/2000
 - 32s - loss: 3773.9221 - val_loss: 16325.2882

Epoch 00420: loss did not improve from 3753.76945
Epoch 421/2000
 - 32s - loss: 3775.7718 - val_loss: 5265.3412

Epoch 00421: loss did not improve from 3753.76945
Epoch 422/2000
 - 32s - loss: 3733.2716 - val_loss: 6701.0978

Epoch 00422: loss improved from 3753.76945 to 3733.27163, saving model to ./weights/_weights.h5
Epoch 423/2000
 - 32s - loss: 3801.0471 - val_loss: 7107.1999

Epoch 00423: loss did not improve from 3733.27163
Epoch 424/2000
 - 33s - loss: 3798.4542 - val_loss: 7307.1688

Epoch 00424: loss did not improve from 3733.27163
Epoch 425/2000
 - 32s - loss: 3839.2216 - val_loss: 5276.6223

Epoch 00425: loss did not improve from 3733.27163
Epoch 426/2000
 - 33s - loss: 3866.0318 - val_loss: 6972.6378

Epoch 00426: loss did not improve from 3733.27163
Epoch 427/2000
 - 32s - loss: 3783.4521 - val_loss: 6304.4532

Epoch 00427: loss did not improve from 3733.27163
Epoch 428/2000
 - 32s - loss: 3687.3946 - val_loss: 11853.5055

Epoch 00428: loss improved from 3733.27163 to 3687.39459, saving model to ./weights/_weights.h5
Epoch 429/2000
 - 32s - loss: 3646.4415 - val_loss: 19390.4327

Epoch 00429: loss improved from 3687.39459 to 3646.44151, saving model to ./weights/_weights.h5
Epoch 430/2000
 - 32s - loss: 3722.7213 - val_loss: 6098.6210

Epoch 00430: loss did not improve from 3646.44151
Epoch 431/2000
 - 32s - loss: 3781.0753 - val_loss: 8648.2374

Epoch 00431: loss did not improve from 3646.44151
Epoch 432/2000
 - 32s - loss: 3791.8625 - val_loss: 6037.0358

Epoch 00432: loss did not improve from 3646.44151
Epoch 433/2000
 - 32s - loss: 3674.9652 - val_loss: 4465.3871

Epoch 00433: loss did not improve from 3646.44151
Epoch 434/2000
 - 32s - loss: 3727.1532 - val_loss: 4584.8798

Epoch 00434: loss did not improve from 3646.44151
Epoch 435/2000
 - 33s - loss: 3695.8176 - val_loss: 5402.7406

Epoch 00435: loss did not improve from 3646.44151
Epoch 436/2000
 - 32s - loss: 3794.0084 - val_loss: 7679.5937

Epoch 00436: loss did not improve from 3646.44151
Epoch 437/2000
 - 33s - loss: 3713.7713 - val_loss: 22895.8156

Epoch 00437: loss did not improve from 3646.44151
Epoch 438/2000
 - 32s - loss: 3692.5745 - val_loss: 6455.3987

Epoch 00438: loss did not improve from 3646.44151
Epoch 439/2000
 - 32s - loss: 3715.4246 - val_loss: 11954.4602

Epoch 00439: loss did not improve from 3646.44151
Epoch 440/2000
 - 32s - loss: 3769.8918 - val_loss: 4762.6673

Epoch 00440: loss did not improve from 3646.44151
Epoch 441/2000
 - 32s - loss: 3655.6535 - val_loss: 4654.5876

Epoch 00441: loss did not improve from 3646.44151
Epoch 442/2000
 - 32s - loss: 3703.1658 - val_loss: 8598.1246

Epoch 00442: loss did not improve from 3646.44151
Epoch 443/2000
 - 32s - loss: 3719.2846 - val_loss: 10376.1285

Epoch 00443: loss did not improve from 3646.44151
Epoch 444/2000
 - 33s - loss: 3793.7494 - val_loss: 11654.5388

Epoch 00444: loss did not improve from 3646.44151
Epoch 445/2000
 - 33s - loss: 3724.7504 - val_loss: 6243.0974

Epoch 00445: loss did not improve from 3646.44151
Epoch 446/2000
 - 32s - loss: 3636.8645 - val_loss: 16610.8877

Epoch 00446: loss improved from 3646.44151 to 3636.86449, saving model to ./weights/_weights.h5
Epoch 447/2000
 - 32s - loss: 3779.1662 - val_loss: 13457.4099

Epoch 00447: loss did not improve from 3636.86449
Epoch 448/2000
 - 32s - loss: 3729.3884 - val_loss: 10992.7779

Epoch 00448: loss did not improve from 3636.86449
Epoch 449/2000
 - 32s - loss: 3687.3923 - val_loss: 4983.9983

Epoch 00449: loss did not improve from 3636.86449
Epoch 450/2000
 - 32s - loss: 3615.6661 - val_loss: 7571.5294

Epoch 00450: loss improved from 3636.86449 to 3615.66609, saving model to ./weights/_weights.h5
Epoch 451/2000
 - 32s - loss: 3745.1137 - val_loss: 5379.5156

Epoch 00451: loss did not improve from 3615.66609
Epoch 452/2000
 - 33s - loss: 3638.2678 - val_loss: 5458.8185

Epoch 00452: loss did not improve from 3615.66609
Epoch 453/2000
 - 32s - loss: 3680.8317 - val_loss: 7157.1589

Epoch 00453: loss did not improve from 3615.66609
Epoch 454/2000
 - 33s - loss: 3751.5156 - val_loss: 4344.3561

Epoch 00454: loss did not improve from 3615.66609
Epoch 455/2000
 - 32s - loss: 3684.5617 - val_loss: 4935.7775

Epoch 00455: loss did not improve from 3615.66609
Epoch 456/2000
 - 32s - loss: 3695.6020 - val_loss: 7058.3142

Epoch 00456: loss did not improve from 3615.66609
Epoch 457/2000
 - 32s - loss: 3593.9882 - val_loss: 5091.5934

Epoch 00457: loss improved from 3615.66609 to 3593.98822, saving model to ./weights/_weights.h5
Epoch 458/2000
 - 32s - loss: 3681.4214 - val_loss: 5371.5513

Epoch 00458: loss did not improve from 3593.98822
Epoch 459/2000
 - 32s - loss: 3747.1263 - val_loss: 7467.7772

Epoch 00459: loss did not improve from 3593.98822
Epoch 460/2000
 - 32s - loss: 3609.4360 - val_loss: 8102.0022

Epoch 00460: loss did not improve from 3593.98822
Epoch 461/2000
 - 33s - loss: 3689.5762 - val_loss: 5157.6612

Epoch 00461: loss did not improve from 3593.98822
Epoch 462/2000
 - 32s - loss: 3672.7451 - val_loss: 5544.4937

Epoch 00462: loss did not improve from 3593.98822
Epoch 463/2000
 - 33s - loss: 3618.9835 - val_loss: 4710.4974

Epoch 00463: loss did not improve from 3593.98822
Epoch 464/2000
 - 32s - loss: 3636.7695 - val_loss: 12262.1607

Epoch 00464: loss did not improve from 3593.98822
Epoch 465/2000
 - 32s - loss: 3650.9762 - val_loss: 4706.6240

Epoch 00465: loss did not improve from 3593.98822
Epoch 466/2000
 - 33s - loss: 3695.7910 - val_loss: 8208.3465

Epoch 00466: loss did not improve from 3593.98822
Epoch 467/2000
 - 32s - loss: 3681.3490 - val_loss: 4668.4137

Epoch 00467: loss did not improve from 3593.98822
Epoch 468/2000
 - 32s - loss: 3737.3898 - val_loss: 4741.4456

Epoch 00468: loss did not improve from 3593.98822
Epoch 469/2000
 - 32s - loss: 3670.2273 - val_loss: 5020.0156

Epoch 00469: loss did not improve from 3593.98822
Epoch 470/2000
 - 32s - loss: 3613.5089 - val_loss: 4863.6543

Epoch 00470: loss did not improve from 3593.98822
Epoch 471/2000
 - 33s - loss: 3820.9085 - val_loss: 23952.4988

Epoch 00471: loss did not improve from 3593.98822
Epoch 472/2000
 - 33s - loss: 4078.8186 - val_loss: 5603.4318

Epoch 00472: loss did not improve from 3593.98822
Epoch 473/2000
 - 32s - loss: 3635.5855 - val_loss: 5722.7598

Epoch 00473: loss did not improve from 3593.98822
Epoch 474/2000
 - 32s - loss: 3584.8557 - val_loss: 4748.2621

Epoch 00474: loss improved from 3593.98822 to 3584.85565, saving model to ./weights/_weights.h5
Epoch 475/2000
 - 32s - loss: 3535.9957 - val_loss: 5105.8661

Epoch 00475: loss improved from 3584.85565 to 3535.99572, saving model to ./weights/_weights.h5
Epoch 476/2000
 - 32s - loss: 3684.6811 - val_loss: 6659.6077

Epoch 00476: loss did not improve from 3535.99572
Epoch 477/2000
 - 32s - loss: 3505.0740 - val_loss: 5238.0015

Epoch 00477: loss improved from 3535.99572 to 3505.07402, saving model to ./weights/_weights.h5
Epoch 478/2000
 - 32s - loss: 3642.4078 - val_loss: 4793.0641

Epoch 00478: loss did not improve from 3505.07402
Epoch 479/2000
 - 32s - loss: 3683.4223 - val_loss: 6537.2603

Epoch 00479: loss did not improve from 3505.07402
Epoch 480/2000
 - 32s - loss: 3633.7453 - val_loss: 7498.6646

Epoch 00480: loss did not improve from 3505.07402
Epoch 481/2000
 - 33s - loss: 3600.2098 - val_loss: 9407.5173

Epoch 00481: loss did not improve from 3505.07402
Epoch 482/2000
 - 33s - loss: 3602.2377 - val_loss: 4713.7819

Epoch 00482: loss did not improve from 3505.07402
Epoch 483/2000
 - 32s - loss: 3601.2316 - val_loss: 6165.0413

Epoch 00483: loss did not improve from 3505.07402
Epoch 484/2000
 - 32s - loss: 3668.9795 - val_loss: 5272.4728

Epoch 00484: loss did not improve from 3505.07402
Epoch 485/2000
 - 32s - loss: 3654.7978 - val_loss: 7345.7699

Epoch 00485: loss did not improve from 3505.07402
Epoch 486/2000
 - 32s - loss: 3627.1775 - val_loss: 6366.2243

Epoch 00486: loss did not improve from 3505.07402
Epoch 487/2000
 - 32s - loss: 3566.1491 - val_loss: 4424.3752

Epoch 00487: loss did not improve from 3505.07402
Epoch 488/2000
 - 32s - loss: 3621.8301 - val_loss: 4993.1112

Epoch 00488: loss did not improve from 3505.07402
Epoch 489/2000
 - 33s - loss: 3599.7385 - val_loss: 10393.3382

Epoch 00489: loss did not improve from 3505.07402
Epoch 490/2000
 - 32s - loss: 3599.7201 - val_loss: 5149.3136

Epoch 00490: loss did not improve from 3505.07402
Epoch 491/2000
 - 33s - loss: 3555.0104 - val_loss: 5208.7822

Epoch 00491: loss did not improve from 3505.07402
Epoch 492/2000
 - 32s - loss: 3626.9572 - val_loss: 10000.9971

Epoch 00492: loss did not improve from 3505.07402
Epoch 493/2000
 - 33s - loss: 3682.3676 - val_loss: 9232.7340

Epoch 00493: loss did not improve from 3505.07402
Epoch 494/2000
 - 32s - loss: 3554.3721 - val_loss: 9045.9373

Epoch 00494: loss did not improve from 3505.07402
Epoch 495/2000
 - 32s - loss: 3703.2606 - val_loss: 6121.7618

Epoch 00495: loss did not improve from 3505.07402
Epoch 496/2000
 - 32s - loss: 3544.6701 - val_loss: 4708.4935

Epoch 00496: loss did not improve from 3505.07402
Epoch 497/2000
 - 32s - loss: 3606.8375 - val_loss: 7293.6183

Epoch 00497: loss did not improve from 3505.07402
Epoch 498/2000
 - 33s - loss: 3578.7084 - val_loss: 12468.3901

Epoch 00498: loss did not improve from 3505.07402
Epoch 499/2000
 - 32s - loss: 3714.4258 - val_loss: 5440.8973

Epoch 00499: loss did not improve from 3505.07402
Epoch 500/2000
 - 33s - loss: 3500.9766 - val_loss: 6636.3102

Epoch 00500: loss improved from 3505.07402 to 3500.97659, saving model to ./weights/_weights.h5
Epoch 501/2000
 - 32s - loss: 3539.1355 - val_loss: 7542.1432

Epoch 00501: loss did not improve from 3500.97659
Epoch 502/2000
 - 32s - loss: 3565.6422 - val_loss: 4987.8255

Epoch 00502: loss did not improve from 3500.97659
Epoch 503/2000
 - 32s - loss: 3529.4921 - val_loss: 4784.3902

Epoch 00503: loss did not improve from 3500.97659
Epoch 504/2000
 - 32s - loss: 3619.9549 - val_loss: 4776.8357

Epoch 00504: loss did not improve from 3500.97659
Epoch 505/2000
 - 32s - loss: 3615.6183 - val_loss: 4457.2049

Epoch 00505: loss did not improve from 3500.97659
Epoch 506/2000
 - 32s - loss: 3566.5137 - val_loss: 21755.2632

Epoch 00506: loss did not improve from 3500.97659
Epoch 507/2000
 - 32s - loss: 3786.5043 - val_loss: 4377.8526

Epoch 00507: loss did not improve from 3500.97659
Epoch 508/2000
 - 32s - loss: 3609.7128 - val_loss: 4647.1299

Epoch 00508: loss did not improve from 3500.97659
Epoch 509/2000
 - 33s - loss: 3485.0762 - val_loss: 5616.1239

Epoch 00509: loss improved from 3500.97659 to 3485.07622, saving model to ./weights/_weights.h5
Epoch 510/2000
 - 33s - loss: 3480.2832 - val_loss: 5111.9167

Epoch 00510: loss improved from 3485.07622 to 3480.28318, saving model to ./weights/_weights.h5
Epoch 511/2000
 - 32s - loss: 3552.1918 - val_loss: 13883.2239

Epoch 00511: loss did not improve from 3480.28318
Epoch 512/2000
 - 32s - loss: 3637.3729 - val_loss: 5053.2234

Epoch 00512: loss did not improve from 3480.28318
Epoch 513/2000
 - 32s - loss: 3473.8034 - val_loss: 5417.0088

Epoch 00513: loss improved from 3480.28318 to 3473.80344, saving model to ./weights/_weights.h5
Epoch 514/2000
 - 32s - loss: 3465.9607 - val_loss: 13663.3470

Epoch 00514: loss improved from 3473.80344 to 3465.96067, saving model to ./weights/_weights.h5
Epoch 515/2000
 - 32s - loss: 3414.6442 - val_loss: 4961.3404

Epoch 00515: loss improved from 3465.96067 to 3414.64418, saving model to ./weights/_weights.h5
Epoch 516/2000
 - 32s - loss: 3521.3445 - val_loss: 4544.9563

Epoch 00516: loss did not improve from 3414.64418
Epoch 517/2000
 - 32s - loss: 3497.6658 - val_loss: 6324.6182

Epoch 00517: loss did not improve from 3414.64418
Epoch 518/2000
 - 32s - loss: 3495.4023 - val_loss: 9861.9873

Epoch 00518: loss did not improve from 3414.64418
Epoch 519/2000
 - 33s - loss: 3552.5442 - val_loss: 5765.7462

Epoch 00519: loss did not improve from 3414.64418
Epoch 520/2000
 - 32s - loss: 3528.4078 - val_loss: 9106.9565

Epoch 00520: loss did not improve from 3414.64418
Epoch 521/2000
 - 32s - loss: 3496.8251 - val_loss: 4430.9840

Epoch 00521: loss did not improve from 3414.64418
Epoch 522/2000
 - 33s - loss: 3435.1396 - val_loss: 8251.4816

Epoch 00522: loss did not improve from 3414.64418
Epoch 523/2000
 - 32s - loss: 3516.4071 - val_loss: 6526.5770

Epoch 00523: loss did not improve from 3414.64418
Epoch 524/2000
 - 32s - loss: 3660.3372 - val_loss: 5389.5681

Epoch 00524: loss did not improve from 3414.64418
Epoch 525/2000
 - 32s - loss: 3546.5042 - val_loss: 6837.0624

Epoch 00525: loss did not improve from 3414.64418
Epoch 526/2000
 - 32s - loss: 3477.9391 - val_loss: 13818.1398

Epoch 00526: loss did not improve from 3414.64418
Epoch 527/2000
 - 32s - loss: 3505.6136 - val_loss: 8054.6435

Epoch 00527: loss did not improve from 3414.64418
Epoch 528/2000
 - 33s - loss: 3406.3636 - val_loss: 4436.9098

Epoch 00528: loss improved from 3414.64418 to 3406.36363, saving model to ./weights/_weights.h5
Epoch 529/2000
 - 32s - loss: 3494.9818 - val_loss: 10900.8088

Epoch 00529: loss did not improve from 3406.36363
Epoch 530/2000
 - 32s - loss: 3546.0809 - val_loss: 6263.9850

Epoch 00530: loss did not improve from 3406.36363
Epoch 531/2000
 - 32s - loss: 3598.2387 - val_loss: 8760.8294

Epoch 00531: loss did not improve from 3406.36363
Epoch 532/2000
 - 32s - loss: 3522.1224 - val_loss: 4793.3141

Epoch 00532: loss did not improve from 3406.36363
Epoch 533/2000
 - 32s - loss: 3461.9258 - val_loss: 5009.5376

Epoch 00533: loss did not improve from 3406.36363
Epoch 534/2000
 - 32s - loss: 3415.7613 - val_loss: 5656.5634

Epoch 00534: loss did not improve from 3406.36363
Epoch 535/2000
 - 32s - loss: 3554.8640 - val_loss: 4453.8143

Epoch 00535: loss did not improve from 3406.36363
Epoch 536/2000
 - 32s - loss: 3488.8915 - val_loss: 5194.1488

Epoch 00536: loss did not improve from 3406.36363
Epoch 537/2000
 - 33s - loss: 3473.3974 - val_loss: 5135.5616

Epoch 00537: loss did not improve from 3406.36363
Epoch 538/2000
 - 32s - loss: 3538.8988 - val_loss: 5141.8153

Epoch 00538: loss did not improve from 3406.36363
Epoch 539/2000
 - 33s - loss: 3437.8239 - val_loss: 6628.9996

Epoch 00539: loss did not improve from 3406.36363
Epoch 540/2000
 - 32s - loss: 3442.1651 - val_loss: 4553.7557

Epoch 00540: loss did not improve from 3406.36363
Epoch 541/2000
 - 32s - loss: 3454.7002 - val_loss: 16062.6153

Epoch 00541: loss did not improve from 3406.36363
Epoch 542/2000
 - 33s - loss: 3583.0674 - val_loss: 4861.7755

Epoch 00542: loss did not improve from 3406.36363
Epoch 543/2000
 - 32s - loss: 3501.2052 - val_loss: 5936.3327

Epoch 00543: loss did not improve from 3406.36363
Epoch 544/2000
 - 32s - loss: 3466.1649 - val_loss: 6864.6261

Epoch 00544: loss did not improve from 3406.36363
Epoch 545/2000
 - 32s - loss: 3448.2915 - val_loss: 8022.0861

Epoch 00545: loss did not improve from 3406.36363
Epoch 546/2000
 - 33s - loss: 3493.4082 - val_loss: 11819.1016

Epoch 00546: loss did not improve from 3406.36363
Epoch 547/2000
 - 33s - loss: 3334.8810 - val_loss: 4779.7928

Epoch 00547: loss improved from 3406.36363 to 3334.88096, saving model to ./weights/_weights.h5
Epoch 548/2000
 - 32s - loss: 3414.2249 - val_loss: 4925.5310

Epoch 00548: loss did not improve from 3334.88096
Epoch 549/2000
 - 32s - loss: 3495.8679 - val_loss: 4635.5014

Epoch 00549: loss did not improve from 3334.88096
Epoch 550/2000
 - 32s - loss: 3409.3916 - val_loss: 6561.8171

Epoch 00550: loss did not improve from 3334.88096
Epoch 551/2000
 - 32s - loss: 3489.8810 - val_loss: 4423.6931

Epoch 00551: loss did not improve from 3334.88096
Epoch 552/2000
 - 32s - loss: 3402.0705 - val_loss: 4554.2223

Epoch 00552: loss did not improve from 3334.88096
Epoch 553/2000
 - 32s - loss: 3458.6394 - val_loss: 4604.9914

Epoch 00553: loss did not improve from 3334.88096
Epoch 554/2000
 - 32s - loss: 3377.2045 - val_loss: 4769.1614

Epoch 00554: loss did not improve from 3334.88096
Epoch 555/2000
 - 32s - loss: 3498.0192 - val_loss: 4536.5967

Epoch 00555: loss did not improve from 3334.88096
Epoch 556/2000
 - 33s - loss: 3377.1523 - val_loss: 7702.0021

Epoch 00556: loss did not improve from 3334.88096
Epoch 557/2000
 - 32s - loss: 3457.4790 - val_loss: 13938.3368

Epoch 00557: loss did not improve from 3334.88096
Epoch 558/2000
 - 32s - loss: 3531.2584 - val_loss: 4627.6286

Epoch 00558: loss did not improve from 3334.88096
Epoch 559/2000
 - 32s - loss: 3469.7800 - val_loss: 4581.4695

Epoch 00559: loss did not improve from 3334.88096
Epoch 560/2000
 - 32s - loss: 3434.0193 - val_loss: 4987.8374

Epoch 00560: loss did not improve from 3334.88096
Epoch 561/2000
 - 32s - loss: 3382.7390 - val_loss: 5708.2479

Epoch 00561: loss did not improve from 3334.88096
Epoch 562/2000
 - 32s - loss: 3348.3473 - val_loss: 7230.5083

Epoch 00562: loss did not improve from 3334.88096
Epoch 563/2000
 - 32s - loss: 3409.2581 - val_loss: 11319.0503

Epoch 00563: loss did not improve from 3334.88096
Epoch 564/2000
 - 32s - loss: 3345.9591 - val_loss: 4527.5727

Epoch 00564: loss did not improve from 3334.88096
Epoch 565/2000
 - 33s - loss: 3353.4838 - val_loss: 8244.2713

Epoch 00565: loss did not improve from 3334.88096
Epoch 566/2000
 - 32s - loss: 3397.9616 - val_loss: 4629.3243

Epoch 00566: loss did not improve from 3334.88096
Epoch 567/2000
 - 32s - loss: 3435.2318 - val_loss: 9813.7026

Epoch 00567: loss did not improve from 3334.88096
Epoch 568/2000
 - 32s - loss: 3426.7475 - val_loss: 9082.5072

Epoch 00568: loss did not improve from 3334.88096
Epoch 569/2000
 - 32s - loss: 3410.0896 - val_loss: 5749.0146

Epoch 00569: loss did not improve from 3334.88096
Epoch 570/2000
 - 32s - loss: 3386.3048 - val_loss: 5702.0573

Epoch 00570: loss did not improve from 3334.88096
Epoch 571/2000
 - 32s - loss: 3279.3676 - val_loss: 4641.8393

Epoch 00571: loss improved from 3334.88096 to 3279.36761, saving model to ./weights/_weights.h5
Epoch 572/2000
 - 32s - loss: 3395.6691 - val_loss: 7435.6417

Epoch 00572: loss did not improve from 3279.36761
Epoch 573/2000
 - 32s - loss: 3423.3047 - val_loss: 5360.1716

Epoch 00573: loss did not improve from 3279.36761
Epoch 574/2000
 - 33s - loss: 3412.2665 - val_loss: 5265.9640

Epoch 00574: loss did not improve from 3279.36761
Epoch 575/2000
 - 32s - loss: 3387.2784 - val_loss: 8602.4549

Epoch 00575: loss did not improve from 3279.36761
Epoch 576/2000
 - 32s - loss: 3445.8962 - val_loss: 5122.3033

Epoch 00576: loss did not improve from 3279.36761
Epoch 577/2000
 - 32s - loss: 3305.3069 - val_loss: 4632.3983

Epoch 00577: loss did not improve from 3279.36761
Epoch 578/2000
 - 33s - loss: 3404.5391 - val_loss: 5990.9109

Epoch 00578: loss did not improve from 3279.36761
Epoch 579/2000
 - 32s - loss: 3304.5866 - val_loss: 5573.9017

Epoch 00579: loss did not improve from 3279.36761
Epoch 580/2000
 - 32s - loss: 3366.4807 - val_loss: 8047.4658

Epoch 00580: loss did not improve from 3279.36761
Epoch 581/2000
 - 32s - loss: 3452.9190 - val_loss: 9286.4516

Epoch 00581: loss did not improve from 3279.36761
Epoch 582/2000
 - 32s - loss: 3342.7852 - val_loss: 4272.5356

Epoch 00582: loss did not improve from 3279.36761
Epoch 583/2000
 - 33s - loss: 3420.7098 - val_loss: 9201.9221

Epoch 00583: loss did not improve from 3279.36761
Epoch 584/2000
 - 33s - loss: 3276.8235 - val_loss: 7601.7247

Epoch 00584: loss improved from 3279.36761 to 3276.82346, saving model to ./weights/_weights.h5
Epoch 585/2000
 - 32s - loss: 3430.8093 - val_loss: 5798.8652

Epoch 00585: loss did not improve from 3276.82346
Epoch 586/2000
 - 33s - loss: 3339.7204 - val_loss: 5482.4141

Epoch 00586: loss did not improve from 3276.82346
Epoch 587/2000
 - 32s - loss: 3394.7305 - val_loss: 10316.0808

Epoch 00587: loss did not improve from 3276.82346
Epoch 588/2000
 - 32s - loss: 3433.8282 - val_loss: 4783.4626

Epoch 00588: loss did not improve from 3276.82346
Epoch 589/2000
 - 32s - loss: 3384.0957 - val_loss: 5966.3806

Epoch 00589: loss did not improve from 3276.82346
Epoch 590/2000
 - 32s - loss: 3387.6889 - val_loss: 5227.1299

Epoch 00590: loss did not improve from 3276.82346
Epoch 591/2000
 - 32s - loss: 3375.3992 - val_loss: 5191.9620

Epoch 00591: loss did not improve from 3276.82346
Epoch 592/2000
 - 32s - loss: 3422.1368 - val_loss: 4797.1007

Epoch 00592: loss did not improve from 3276.82346
Epoch 593/2000
 - 33s - loss: 3281.2577 - val_loss: 5978.2178

Epoch 00593: loss did not improve from 3276.82346
Epoch 594/2000
 - 32s - loss: 3394.2698 - val_loss: 14819.0919

Epoch 00594: loss did not improve from 3276.82346
Epoch 595/2000
 - 32s - loss: 3342.2954 - val_loss: 4269.0029

Epoch 00595: loss did not improve from 3276.82346
Epoch 596/2000
 - 32s - loss: 3350.3074 - val_loss: 6291.8697

Epoch 00596: loss did not improve from 3276.82346
Epoch 597/2000
 - 32s - loss: 3319.8251 - val_loss: 10645.5282

Epoch 00597: loss did not improve from 3276.82346
Epoch 598/2000
 - 32s - loss: 3297.6687 - val_loss: 14798.6212

Epoch 00598: loss did not improve from 3276.82346
Epoch 599/2000
 - 32s - loss: 3495.9980 - val_loss: 5937.5015

Epoch 00599: loss did not improve from 3276.82346
Epoch 600/2000
 - 32s - loss: 3371.5543 - val_loss: 13820.9171

Epoch 00600: loss did not improve from 3276.82346
Epoch 601/2000
 - 32s - loss: 3402.6918 - val_loss: 6012.5441

Epoch 00601: loss did not improve from 3276.82346
Epoch 602/2000
 - 33s - loss: 3424.2766 - val_loss: 11168.3958

Epoch 00602: loss did not improve from 3276.82346
Epoch 603/2000
 - 32s - loss: 3356.0372 - val_loss: 8256.9863

Epoch 00603: loss did not improve from 3276.82346
Epoch 604/2000
 - 32s - loss: 3337.6766 - val_loss: 8741.0923

Epoch 00604: loss did not improve from 3276.82346
Epoch 605/2000
 - 32s - loss: 3336.2222 - val_loss: 6201.6311

Epoch 00605: loss did not improve from 3276.82346
Epoch 606/2000
 - 32s - loss: 3283.2019 - val_loss: 4606.2012

Epoch 00606: loss did not improve from 3276.82346
Epoch 607/2000
 - 32s - loss: 3281.8304 - val_loss: 7950.9902

Epoch 00607: loss did not improve from 3276.82346
Epoch 608/2000
 - 32s - loss: 3376.6017 - val_loss: 4797.6098

Epoch 00608: loss did not improve from 3276.82346
Epoch 609/2000
 - 32s - loss: 3334.2618 - val_loss: 12913.2737

Epoch 00609: loss did not improve from 3276.82346
Epoch 610/2000
 - 33s - loss: 3345.0163 - val_loss: 5504.6785

Epoch 00610: loss did not improve from 3276.82346
Epoch 611/2000
 - 33s - loss: 3352.1445 - val_loss: 15732.1441

Epoch 00611: loss did not improve from 3276.82346
Epoch 612/2000
 - 32s - loss: 3345.3627 - val_loss: 5608.3256

Epoch 00612: loss did not improve from 3276.82346
Epoch 613/2000
 - 32s - loss: 3276.0945 - val_loss: 4925.0141

Epoch 00613: loss improved from 3276.82346 to 3276.09449, saving model to ./weights/_weights.h5
Epoch 614/2000
 - 32s - loss: 3360.0587 - val_loss: 4463.4616

Epoch 00614: loss did not improve from 3276.09449
Epoch 615/2000
 - 32s - loss: 3293.6272 - val_loss: 5220.6213

Epoch 00615: loss did not improve from 3276.09449
Epoch 616/2000
 - 32s - loss: 3340.7125 - val_loss: 13990.8629

Epoch 00616: loss did not improve from 3276.09449
Epoch 617/2000
 - 32s - loss: 3357.5268 - val_loss: 4696.9888

Epoch 00617: loss did not improve from 3276.09449
Epoch 618/2000
 - 32s - loss: 3275.1354 - val_loss: 11661.4562

Epoch 00618: loss improved from 3276.09449 to 3275.13538, saving model to ./weights/_weights.h5
Epoch 619/2000
 - 32s - loss: 3400.8820 - val_loss: 17154.2090

Epoch 00619: loss did not improve from 3275.13538
Epoch 620/2000
 - 33s - loss: 3292.3584 - val_loss: 5131.6617

Epoch 00620: loss did not improve from 3275.13538
Epoch 621/2000
 - 33s - loss: 3337.1095 - val_loss: 6808.7479

Epoch 00621: loss did not improve from 3275.13538
Epoch 622/2000
 - 32s - loss: 3342.8690 - val_loss: 28086.9587

Epoch 00622: loss did not improve from 3275.13538
Epoch 623/2000
 - 32s - loss: 3329.7272 - val_loss: 4842.8766

Epoch 00623: loss did not improve from 3275.13538
Epoch 624/2000
 - 32s - loss: 3268.5797 - val_loss: 5059.9272

Epoch 00624: loss improved from 3275.13538 to 3268.57970, saving model to ./weights/_weights.h5
Epoch 625/2000
 - 32s - loss: 3347.0336 - val_loss: 5376.2744

Epoch 00625: loss did not improve from 3268.57970
Epoch 626/2000
 - 32s - loss: 3324.6001 - val_loss: 5402.3098

Epoch 00626: loss did not improve from 3268.57970
Epoch 627/2000
 - 32s - loss: 3202.8779 - val_loss: 4497.3715

Epoch 00627: loss improved from 3268.57970 to 3202.87793, saving model to ./weights/_weights.h5
Epoch 628/2000
 - 33s - loss: 3251.2876 - val_loss: 5793.4417

Epoch 00628: loss did not improve from 3202.87793
Epoch 629/2000
 - 32s - loss: 3217.5623 - val_loss: 4869.1024

Epoch 00629: loss did not improve from 3202.87793
Epoch 630/2000
 - 33s - loss: 3339.4945 - val_loss: 5369.5875

Epoch 00630: loss did not improve from 3202.87793
Epoch 631/2000
 - 32s - loss: 3326.8190 - val_loss: 6420.2626

Epoch 00631: loss did not improve from 3202.87793
Epoch 632/2000
 - 32s - loss: 3314.0836 - val_loss: 17888.3199

Epoch 00632: loss did not improve from 3202.87793
Epoch 633/2000
 - 33s - loss: 3368.4272 - val_loss: 5325.6458

Epoch 00633: loss did not improve from 3202.87793
Epoch 634/2000
 - 32s - loss: 3206.3519 - val_loss: 4786.9759

Epoch 00634: loss did not improve from 3202.87793
Epoch 635/2000
 - 32s - loss: 3322.2471 - val_loss: 13484.3770

Epoch 00635: loss did not improve from 3202.87793
Epoch 636/2000
 - 32s - loss: 3208.4199 - val_loss: 5281.3465

Epoch 00636: loss did not improve from 3202.87793
Epoch 637/2000
 - 32s - loss: 3256.5544 - val_loss: 4827.9653

Epoch 00637: loss did not improve from 3202.87793
Epoch 638/2000
 - 32s - loss: 3374.3329 - val_loss: 12420.5806

Epoch 00638: loss did not improve from 3202.87793
Epoch 639/2000
 - 33s - loss: 3310.2773 - val_loss: 5759.5181

Epoch 00639: loss did not improve from 3202.87793
Epoch 640/2000
 - 33s - loss: 3245.5262 - val_loss: 11133.2086

Epoch 00640: loss did not improve from 3202.87793
Epoch 641/2000
 - 32s - loss: 3180.3059 - val_loss: 4637.2048

Epoch 00641: loss improved from 3202.87793 to 3180.30591, saving model to ./weights/_weights.h5
Epoch 642/2000
 - 32s - loss: 3246.2967 - val_loss: 4444.4400

Epoch 00642: loss did not improve from 3180.30591
Epoch 643/2000
 - 32s - loss: 3309.3844 - val_loss: 5486.8160

Epoch 00643: loss did not improve from 3180.30591
Epoch 644/2000
 - 32s - loss: 3253.2772 - val_loss: 6160.8133

Epoch 00644: loss did not improve from 3180.30591
Epoch 645/2000
 - 32s - loss: 3299.5749 - val_loss: 24329.4573

Epoch 00645: loss did not improve from 3180.30591
Epoch 646/2000
 - 32s - loss: 3260.0562 - val_loss: 8574.4527

Epoch 00646: loss did not improve from 3180.30591
Epoch 647/2000
 - 32s - loss: 3237.0754 - val_loss: 9964.9095

Epoch 00647: loss did not improve from 3180.30591
Epoch 648/2000
 - 33s - loss: 3165.4822 - val_loss: 4893.6403

Epoch 00648: loss improved from 3180.30591 to 3165.48221, saving model to ./weights/_weights.h5
Epoch 649/2000
 - 33s - loss: 3268.3699 - val_loss: 5765.6703

Epoch 00649: loss did not improve from 3165.48221
Epoch 650/2000
 - 32s - loss: 3238.0288 - val_loss: 14261.9343

Epoch 00650: loss did not improve from 3165.48221
Epoch 651/2000
 - 32s - loss: 3254.6094 - val_loss: 4514.0868

Epoch 00651: loss did not improve from 3165.48221
Epoch 652/2000
 - 32s - loss: 3375.8726 - val_loss: 5591.8950

Epoch 00652: loss did not improve from 3165.48221
Epoch 653/2000
 - 32s - loss: 3108.5584 - val_loss: 7805.2859

Epoch 00653: loss improved from 3165.48221 to 3108.55840, saving model to ./weights/_weights.h5
Epoch 654/2000
 - 32s - loss: 3273.0416 - val_loss: 5642.7299

Epoch 00654: loss did not improve from 3108.55840
Epoch 655/2000
 - 32s - loss: 3247.8612 - val_loss: 4441.0390

Epoch 00655: loss did not improve from 3108.55840
Epoch 656/2000
 - 32s - loss: 3261.9893 - val_loss: 5191.4504

Epoch 00656: loss did not improve from 3108.55840
Epoch 657/2000
 - 32s - loss: 3149.3598 - val_loss: 6292.6069

Epoch 00657: loss did not improve from 3108.55840
Epoch 658/2000
 - 33s - loss: 3203.9499 - val_loss: 5979.2950

Epoch 00658: loss did not improve from 3108.55840
Epoch 659/2000
 - 32s - loss: 3159.9686 - val_loss: 5191.5533

Epoch 00659: loss did not improve from 3108.55840
Epoch 660/2000
 - 32s - loss: 3320.2992 - val_loss: 15283.0461

Epoch 00660: loss did not improve from 3108.55840
Epoch 661/2000
 - 32s - loss: 3239.0010 - val_loss: 4446.4346

Epoch 00661: loss did not improve from 3108.55840
Epoch 662/2000
 - 32s - loss: 3269.7842 - val_loss: 5022.8650

Epoch 00662: loss did not improve from 3108.55840
Epoch 663/2000
 - 32s - loss: 3259.3171 - val_loss: 5508.6169

Epoch 00663: loss did not improve from 3108.55840
Epoch 664/2000
 - 32s - loss: 3331.9439 - val_loss: 4887.6288

Epoch 00664: loss did not improve from 3108.55840
Epoch 665/2000
 - 33s - loss: 3270.9769 - val_loss: 4874.5712

Epoch 00665: loss did not improve from 3108.55840
Epoch 666/2000
 - 32s - loss: 3177.2122 - val_loss: 4311.8188

Epoch 00666: loss did not improve from 3108.55840
Epoch 667/2000
 - 33s - loss: 3254.1298 - val_loss: 18749.6155

Epoch 00667: loss did not improve from 3108.55840
Epoch 668/2000
 - 32s - loss: 3565.8964 - val_loss: 6383.8222

Epoch 00668: loss did not improve from 3108.55840
Epoch 669/2000
 - 32s - loss: 3192.7026 - val_loss: 7486.9775

Epoch 00669: loss did not improve from 3108.55840
Epoch 670/2000
 - 32s - loss: 3149.6165 - val_loss: 4665.3828

Epoch 00670: loss did not improve from 3108.55840
Epoch 671/2000
 - 32s - loss: 3135.2344 - val_loss: 12778.9072

Epoch 00671: loss did not improve from 3108.55840
Epoch 672/2000
 - 32s - loss: 3217.1426 - val_loss: 5230.5253

Epoch 00672: loss did not improve from 3108.55840
Epoch 673/2000
 - 32s - loss: 3219.6069 - val_loss: 4440.7978

Epoch 00673: loss did not improve from 3108.55840
Epoch 674/2000
 - 32s - loss: 3164.5441 - val_loss: 4652.4023

Epoch 00674: loss did not improve from 3108.55840
Epoch 675/2000
 - 33s - loss: 3245.7852 - val_loss: 6081.7804

Epoch 00675: loss did not improve from 3108.55840
Epoch 676/2000
 - 33s - loss: 3176.4620 - val_loss: 6428.4648

Epoch 00676: loss did not improve from 3108.55840
Epoch 677/2000
 - 32s - loss: 3216.9446 - val_loss: 6856.2285

Epoch 00677: loss did not improve from 3108.55840
Epoch 678/2000
 - 32s - loss: 3207.5871 - val_loss: 5007.1542

Epoch 00678: loss did not improve from 3108.55840
Epoch 679/2000
 - 32s - loss: 3226.7881 - val_loss: 4821.2905

Epoch 00679: loss did not improve from 3108.55840
Epoch 680/2000
 - 32s - loss: 3141.2896 - val_loss: 21814.3022

Epoch 00680: loss did not improve from 3108.55840
Epoch 681/2000
 - 32s - loss: 3225.9127 - val_loss: 5241.4130

Epoch 00681: loss did not improve from 3108.55840
Epoch 682/2000
 - 32s - loss: 3137.7320 - val_loss: 4482.0373

Epoch 00682: loss did not improve from 3108.55840
Epoch 683/2000
 - 32s - loss: 3156.2219 - val_loss: 4622.4702

Epoch 00683: loss did not improve from 3108.55840
Epoch 684/2000
 - 32s - loss: 3159.9975 - val_loss: 6105.5104

Epoch 00684: loss did not improve from 3108.55840
Epoch 685/2000
 - 33s - loss: 3153.3602 - val_loss: 5379.3158

Epoch 00685: loss did not improve from 3108.55840
Epoch 686/2000
 - 33s - loss: 3372.7959 - val_loss: 8322.6597

Epoch 00686: loss did not improve from 3108.55840
Epoch 687/2000
 - 32s - loss: 3242.1380 - val_loss: 5737.4879

Epoch 00687: loss did not improve from 3108.55840
Epoch 688/2000
 - 32s - loss: 3182.6307 - val_loss: 5436.3836

Epoch 00688: loss did not improve from 3108.55840
Epoch 689/2000
 - 33s - loss: 3122.4304 - val_loss: 8815.9866

Epoch 00689: loss did not improve from 3108.55840
Epoch 690/2000
 - 32s - loss: 3167.4695 - val_loss: 8382.4993

Epoch 00690: loss did not improve from 3108.55840
Epoch 691/2000
 - 32s - loss: 3213.7713 - val_loss: 9430.4902

Epoch 00691: loss did not improve from 3108.55840
Epoch 692/2000
 - 32s - loss: 3078.0230 - val_loss: 4137.0498

Epoch 00692: loss improved from 3108.55840 to 3078.02297, saving model to ./weights/_weights.h5
Epoch 693/2000
 - 32s - loss: 3079.7987 - val_loss: 5074.1772

Epoch 00693: loss did not improve from 3078.02297
Epoch 694/2000
 - 32s - loss: 3148.0590 - val_loss: 14620.7667

Epoch 00694: loss did not improve from 3078.02297
Epoch 695/2000
 - 33s - loss: 3143.9538 - val_loss: 5092.5668

Epoch 00695: loss did not improve from 3078.02297
Epoch 696/2000
 - 32s - loss: 3118.2685 - val_loss: 5748.9840

Epoch 00696: loss did not improve from 3078.02297
Epoch 697/2000
 - 33s - loss: 3177.8536 - val_loss: 30578.6959

Epoch 00697: loss did not improve from 3078.02297
Epoch 698/2000
 - 32s - loss: 3318.0400 - val_loss: 4353.9841

Epoch 00698: loss did not improve from 3078.02297
Epoch 699/2000
 - 32s - loss: 3088.8965 - val_loss: 5007.1203

Epoch 00699: loss did not improve from 3078.02297
Epoch 700/2000
 - 32s - loss: 3161.2028 - val_loss: 5522.3717

Epoch 00700: loss did not improve from 3078.02297
Epoch 701/2000
 - 32s - loss: 3100.4209 - val_loss: 4358.5425

Epoch 00701: loss did not improve from 3078.02297
Epoch 702/2000
 - 32s - loss: 3207.3169 - val_loss: 6356.3149

Epoch 00702: loss did not improve from 3078.02297
Epoch 703/2000
 - 32s - loss: 3158.9970 - val_loss: 4608.5647

Epoch 00703: loss did not improve from 3078.02297
Epoch 704/2000
 - 33s - loss: 3172.1611 - val_loss: 11484.2002

Epoch 00704: loss did not improve from 3078.02297
Epoch 705/2000
 - 32s - loss: 3269.7368 - val_loss: 4635.7140

Epoch 00705: loss did not improve from 3078.02297
Epoch 706/2000
 - 32s - loss: 3073.6794 - val_loss: 13136.4303

Epoch 00706: loss improved from 3078.02297 to 3073.67944, saving model to ./weights/_weights.h5
Epoch 707/2000
 - 32s - loss: 3071.5871 - val_loss: 6044.9989

Epoch 00707: loss improved from 3073.67944 to 3071.58714, saving model to ./weights/_weights.h5
Epoch 708/2000
 - 32s - loss: 3105.0472 - val_loss: 6153.9698

Epoch 00708: loss did not improve from 3071.58714
Epoch 709/2000
 - 32s - loss: 3171.1828 - val_loss: 6344.9310

Epoch 00709: loss did not improve from 3071.58714
Epoch 710/2000
 - 32s - loss: 3127.3722 - val_loss: 5609.1354

Epoch 00710: loss did not improve from 3071.58714
Epoch 711/2000
 - 32s - loss: 3069.9291 - val_loss: 7018.6682

Epoch 00711: loss improved from 3071.58714 to 3069.92908, saving model to ./weights/_weights.h5
Epoch 712/2000
 - 32s - loss: 3075.6283 - val_loss: 7312.4556

Epoch 00712: loss did not improve from 3069.92908
Epoch 713/2000
 - 33s - loss: 3250.7918 - val_loss: 15751.0900

Epoch 00713: loss did not improve from 3069.92908
Epoch 714/2000
 - 32s - loss: 3113.0637 - val_loss: 4682.8610

Epoch 00714: loss did not improve from 3069.92908
Epoch 715/2000
 - 32s - loss: 3214.8951 - val_loss: 9408.6562

Epoch 00715: loss did not improve from 3069.92908
Epoch 716/2000
 - 32s - loss: 3138.6274 - val_loss: 4911.1637

Epoch 00716: loss did not improve from 3069.92908
Epoch 717/2000
 - 32s - loss: 3152.2259 - val_loss: 4719.2909

Epoch 00717: loss did not improve from 3069.92908
Epoch 718/2000
 - 32s - loss: 3152.0686 - val_loss: 4686.9648

Epoch 00718: loss did not improve from 3069.92908
Epoch 719/2000
 - 34s - loss: 3103.0269 - val_loss: 4962.7946
Using TensorFlow backend.

Epoch 00719: loss did not improve from 3069.92908
Epoch 720/2000
Traceback (most recent call last):
  File "all_datasets_training.py", line 276, in <module>
    normalize_timeseries=normalize_dataset)
  File "/home/kiototeko/tareas/vibrometry_laser/LSTM-FCN/utils/keras_utils.py", line 134, in train_model
    model.fit(np.expand_dims(X_train,1), y_train, batch_size=batch_size, epochs=epochs, callbacks=callback_list, verbose=2, validation_data=(np.expand_dims(X_test,1), y_test))
  File "/home/kiototeko/miniconda3/envs/lstmfcn/lib/python3.6/site-packages/keras/engine/training.py", line 1239, in fit
    validation_freq=validation_freq)
  File "/home/kiototeko/miniconda3/envs/lstmfcn/lib/python3.6/site-packages/keras/engine/training_arrays.py", line 196, in fit_loop
    outs = fit_function(ins_batch)
  File "/home/kiototeko/miniconda3/envs/lstmfcn/lib/python3.6/site-packages/tensorflow/python/keras/backend.py", line 3792, in __call__
    outputs = self._graph_fn(*converted_inputs)
  File "/home/kiototeko/miniconda3/envs/lstmfcn/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 1605, in __call__
    return self._call_impl(args, kwargs)
  File "/home/kiototeko/miniconda3/envs/lstmfcn/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 1645, in _call_impl
    return self._call_flat(args, self.captured_inputs, cancellation_manager)
  File "/home/kiototeko/miniconda3/envs/lstmfcn/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 1746, in _call_flat
    ctx, args, cancellation_manager=cancellation_manager))
  File "/home/kiototeko/miniconda3/envs/lstmfcn/lib/python3.6/site-packages/tensorflow/python/eager/function.py", line 598, in call
    ctx=ctx)
  File "/home/kiototeko/miniconda3/envs/lstmfcn/lib/python3.6/site-packages/tensorflow/python/eager/execute.py", line 60, in quick_execute
    inputs, attrs, num_outputs)
KeyboardInterrupt
